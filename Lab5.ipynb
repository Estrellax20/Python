{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h2q27gKz1H20"
      },
      "source": [
        "##### Copyright 2019 The TensorFlow Authors."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "TUfAcER1oUS6"
      },
      "outputs": [],
      "source": [
        "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gb7qyhNL1yWt"
      },
      "source": [
        "# Image classification with TensorFlow Lite Model Maker"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nDABAblytltI"
      },
      "source": [
        "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://www.tensorflow.org/lite/models/modify/model_maker/image_classification\"><img src=\"https://www.tensorflow.org/images/tf_logo_32px.png\" />View on TensorFlow.org</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/tensorflow/blob/master/tensorflow/lite/g3doc/models/modify/model_maker/image_classification.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Run in Google Colab</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/g3doc/models/modify/model_maker/image_classification.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />View source on GitHub</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a href=\"https://storage.googleapis.com/tensorflow_docs/tensorflow/tensorflow/lite/g3doc/models/modify/model_maker/image_classification.ipynb\"><img src=\"https://www.tensorflow.org/images/download_logo_32px.png\" />Download notebook</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a href=\"https://tfhub.dev/google/imagenet/inception_v3/feature_vector/1\"><img src=\"https://www.tensorflow.org/images/hub_logo_32px.png\" />See TF Hub model</a>\n",
        "  </td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m86-Nh4pMHqY"
      },
      "source": [
        "The [TensorFlow Lite Model Maker library](https://www.tensorflow.org/lite/models/modify/model_maker) simplifies the process of adapting and converting a TensorFlow neural-network model to particular input data when deploying this model for on-device ML applications.\n",
        "\n",
        "This notebook shows an end-to-end example that utilizes this Model Maker library to illustrate the adaption and conversion of a commonly-used image classification model to classify flowers on a mobile device."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bcLF2PKkSbV3"
      },
      "source": [
        "## Prerequisites\n",
        "\n",
        "To run this example, we first need to install several required packages, including Model Maker package that in GitHub [repo](https://github.com/tensorflow/examples/tree/master/tensorflow_examples/lite/model_maker)."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python --version"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nlOKqSARFQTp",
        "outputId": "1964db85-50a1-445f-b7df-0253497c6aa6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Python 3.10.12\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!sudo update-alternatives --install /usr/bin/python3 python3 /usr/bin/python3.8 1"
      ],
      "metadata": {
        "id": "V7MiXf5WFaMw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!sudo update-alternatives --config python3"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SmZjvggIFcNd",
        "outputId": "59fa36b1-3b10-46f7-b02a-8d94c2cb1e2c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 2 choices for the alternative python3 (providing /usr/bin/python3).\n",
            "\n",
            "  Selection    Path                 Priority   Status\n",
            "------------------------------------------------------------\n",
            "* 0            /usr/bin/python3.10   2         auto mode\n",
            "  1            /usr/bin/python3.10   2         manual mode\n",
            "  2            /usr/bin/python3.8    1         manual mode\n",
            "\n",
            "Press <enter> to keep the current choice[*], or type selection number: 2\n",
            "update-alternatives: using /usr/bin/python3.8 to provide /usr/bin/python3 (python3) in manual mode\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 --version"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3U85Hk26Fefb",
        "outputId": "e2265546-94d5-4b3d-8c83-3a79a91c6612"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Python 3.8.10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!sudo apt install python3-pip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HNHhdC7hFjD2",
        "outputId": "85975705-07b3-49cb-a2b5-26f50f109454"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  python-pip-whl python3-setuptools python3-wheel\n",
            "Suggested packages:\n",
            "  python-setuptools-doc\n",
            "The following NEW packages will be installed:\n",
            "  python-pip-whl python3-pip python3-setuptools python3-wheel\n",
            "0 upgraded, 4 newly installed, 0 to remove and 15 not upgraded.\n",
            "Need to get 2,389 kB of archives.\n",
            "After this operation, 4,933 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu focal-updates/universe amd64 python-pip-whl all 20.0.2-5ubuntu1.9 [1,805 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 python3-setuptools all 45.2.0-1ubuntu0.1 [330 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu focal-updates/universe amd64 python3-wheel all 0.34.2-1ubuntu0.1 [23.9 kB]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu focal-updates/universe amd64 python3-pip all 20.0.2-5ubuntu1.9 [231 kB]\n",
            "Fetched 2,389 kB in 0s (17.0 MB/s)\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 76, <> line 4.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "Selecting previously unselected package python-pip-whl.\n",
            "(Reading database ... 123069 files and directories currently installed.)\n",
            "Preparing to unpack .../python-pip-whl_20.0.2-5ubuntu1.9_all.deb ...\n",
            "Unpacking python-pip-whl (20.0.2-5ubuntu1.9) ...\n",
            "Selecting previously unselected package python3-setuptools.\n",
            "Preparing to unpack .../python3-setuptools_45.2.0-1ubuntu0.1_all.deb ...\n",
            "Unpacking python3-setuptools (45.2.0-1ubuntu0.1) ...\n",
            "Selecting previously unselected package python3-wheel.\n",
            "Preparing to unpack .../python3-wheel_0.34.2-1ubuntu0.1_all.deb ...\n",
            "Unpacking python3-wheel (0.34.2-1ubuntu0.1) ...\n",
            "Selecting previously unselected package python3-pip.\n",
            "Preparing to unpack .../python3-pip_20.0.2-5ubuntu1.9_all.deb ...\n",
            "Unpacking python3-pip (20.0.2-5ubuntu1.9) ...\n",
            "Setting up python3-setuptools (45.2.0-1ubuntu0.1) ...\n",
            "Setting up python3-wheel (0.34.2-1ubuntu0.1) ...\n",
            "Setting up python-pip-whl (20.0.2-5ubuntu1.9) ...\n",
            "Setting up python3-pip (20.0.2-5ubuntu1.9) ...\n",
            "Processing triggers for man-db (2.9.1-1) ...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install packaging~=20.9"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3pchM4fWI6ul",
        "outputId": "2c186f6e-aac9-4b77-f778-969eeba194b0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting packaging~=20.9\n",
            "  Downloading packaging-20.9-py2.py3-none-any.whl (40 kB)\n",
            "\u001b[K     |████████████████████████████████| 40 kB 4.7 MB/s \n",
            "\u001b[?25hCollecting pyparsing>=2.0.2\n",
            "  Downloading pyparsing-3.0.9-py3-none-any.whl (98 kB)\n",
            "\u001b[K     |████████████████████████████████| 98 kB 5.8 MB/s \n",
            "\u001b[?25hInstalling collected packages: pyparsing, packaging\n",
            "Successfully installed packaging-20.9 pyparsing-3.0.9\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install numpy==1.23"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Csi1vuVEHJ1A",
        "outputId": "ecf6c514-c493-4ce0-cf3b-fd807cf5b38f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting numpy==1.23\n",
            "  Downloading numpy-1.23.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 17.1 MB 10.0 MB/s \n",
            "\u001b[?25hInstalling collected packages: numpy\n",
            "Successfully installed numpy-1.23.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade keras==2.8.0rc0\n",
        "!pip install --upgrade tensorboard==2.8.0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "rPn6J6wqKAOM",
        "outputId": "02a314ff-e2c0-4119-df7b-01ceecfc22da"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting keras==2.8.0rc0\n",
            "  Downloading keras-2.8.0rc0-py2.py3-none-any.whl (1.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.4 MB 9.4 MB/s \n",
            "\u001b[?25hInstalling collected packages: keras\n",
            "Successfully installed keras-2.8.0rc0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting tensorboard==2.8.0\n",
            "  Downloading tensorboard-2.8.0-py3-none-any.whl (5.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 5.8 MB 14.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: wheel>=0.26 in /usr/lib/python3/dist-packages (from tensorboard==2.8.0) (0.34.2)\n",
            "Collecting markdown>=2.6.8\n",
            "  Downloading Markdown-3.4.3-py3-none-any.whl (93 kB)\n",
            "\u001b[K     |████████████████████████████████| 93 kB 2.2 MB/s \n",
            "\u001b[?25hCollecting google-auth<3,>=1.6.3\n",
            "  Downloading google_auth-2.20.0-py2.py3-none-any.whl (181 kB)\n",
            "\u001b[K     |████████████████████████████████| 181 kB 77.5 MB/s \n",
            "\u001b[?25hCollecting werkzeug>=0.11.15\n",
            "  Downloading Werkzeug-2.3.6-py3-none-any.whl (242 kB)\n",
            "\u001b[K     |████████████████████████████████| 242 kB 76.5 MB/s \n",
            "\u001b[?25hCollecting grpcio>=1.24.3\n",
            "  Downloading grpcio-1.54.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 5.1 MB 59.3 MB/s \n",
            "\u001b[?25hCollecting protobuf>=3.6.0\n",
            "  Downloading protobuf-4.23.3-cp37-abi3-manylinux2014_x86_64.whl (304 kB)\n",
            "\u001b[K     |████████████████████████████████| 304 kB 63.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: numpy>=1.12.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard==2.8.0) (1.23.0)\n",
            "Requirement already satisfied, skipping upgrade: setuptools>=41.0.0 in /usr/lib/python3/dist-packages (from tensorboard==2.8.0) (45.2.0)\n",
            "Collecting tensorboard-data-server<0.7.0,>=0.6.0\n",
            "  Downloading tensorboard_data_server-0.6.1-py3-none-manylinux2010_x86_64.whl (4.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.9 MB 57.9 MB/s \n",
            "\u001b[?25hCollecting tensorboard-plugin-wit>=1.6.0\n",
            "  Downloading tensorboard_plugin_wit-1.8.1-py3-none-any.whl (781 kB)\n",
            "\u001b[K     |████████████████████████████████| 781 kB 65.9 MB/s \n",
            "\u001b[?25hCollecting google-auth-oauthlib<0.5,>=0.4.1\n",
            "  Downloading google_auth_oauthlib-0.4.6-py2.py3-none-any.whl (18 kB)\n",
            "Collecting absl-py>=0.4\n",
            "  Downloading absl_py-1.4.0-py3-none-any.whl (126 kB)\n",
            "\u001b[K     |████████████████████████████████| 126 kB 61.7 MB/s \n",
            "\u001b[?25hCollecting requests<3,>=2.21.0\n",
            "  Downloading requests-2.31.0-py3-none-any.whl (62 kB)\n",
            "\u001b[K     |████████████████████████████████| 62 kB 1.2 MB/s \n",
            "\u001b[?25hCollecting importlib-metadata>=4.4; python_version < \"3.10\"\n",
            "  Downloading importlib_metadata-6.6.0-py3-none-any.whl (22 kB)\n",
            "Collecting cachetools<6.0,>=2.0.0\n",
            "  Downloading cachetools-5.3.1-py3-none-any.whl (9.3 kB)\n",
            "Collecting pyasn1-modules>=0.2.1\n",
            "  Downloading pyasn1_modules-0.3.0-py2.py3-none-any.whl (181 kB)\n",
            "\u001b[K     |████████████████████████████████| 181 kB 65.3 MB/s \n",
            "\u001b[?25hCollecting six>=1.9.0\n",
            "  Downloading six-1.16.0-py2.py3-none-any.whl (11 kB)\n",
            "Collecting urllib3<2.0\n",
            "  Downloading urllib3-1.26.16-py2.py3-none-any.whl (143 kB)\n",
            "\u001b[K     |████████████████████████████████| 143 kB 79.3 MB/s \n",
            "\u001b[?25hCollecting rsa<5,>=3.1.4\n",
            "  Downloading rsa-4.9-py3-none-any.whl (34 kB)\n",
            "Collecting MarkupSafe>=2.1.1\n",
            "  Downloading MarkupSafe-2.1.3-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (25 kB)\n",
            "Collecting requests-oauthlib>=0.7.0\n",
            "  Downloading requests_oauthlib-1.3.1-py2.py3-none-any.whl (23 kB)\n",
            "Collecting charset-normalizer<4,>=2\n",
            "  Downloading charset_normalizer-3.1.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (195 kB)\n",
            "\u001b[K     |████████████████████████████████| 195 kB 66.7 MB/s \n",
            "\u001b[?25hCollecting idna<4,>=2.5\n",
            "  Downloading idna-3.4-py3-none-any.whl (61 kB)\n",
            "\u001b[K     |████████████████████████████████| 61 kB 12 kB/s \n",
            "\u001b[?25hCollecting certifi>=2017.4.17\n",
            "  Downloading certifi-2023.5.7-py3-none-any.whl (156 kB)\n",
            "\u001b[K     |████████████████████████████████| 156 kB 65.9 MB/s \n",
            "\u001b[?25hCollecting zipp>=0.5\n",
            "  Downloading zipp-3.15.0-py3-none-any.whl (6.8 kB)\n",
            "Collecting pyasn1<0.6.0,>=0.4.6\n",
            "  Downloading pyasn1-0.5.0-py2.py3-none-any.whl (83 kB)\n",
            "\u001b[K     |████████████████████████████████| 83 kB 2.7 MB/s \n",
            "\u001b[?25hCollecting oauthlib>=3.0.0\n",
            "  Downloading oauthlib-3.2.2-py3-none-any.whl (151 kB)\n",
            "\u001b[K     |████████████████████████████████| 151 kB 65.0 MB/s \n",
            "\u001b[?25hInstalling collected packages: zipp, importlib-metadata, markdown, cachetools, pyasn1, pyasn1-modules, six, urllib3, rsa, google-auth, MarkupSafe, werkzeug, grpcio, protobuf, tensorboard-data-server, tensorboard-plugin-wit, oauthlib, charset-normalizer, idna, certifi, requests, requests-oauthlib, google-auth-oauthlib, absl-py, tensorboard\n",
            "Successfully installed MarkupSafe-2.1.3 absl-py-1.4.0 cachetools-5.3.1 certifi-2023.5.7 charset-normalizer-3.1.0 google-auth-2.20.0 google-auth-oauthlib-0.4.6 grpcio-1.54.2 idna-3.4 importlib-metadata-6.6.0 markdown-3.4.3 oauthlib-3.2.2 protobuf-4.23.3 pyasn1-0.5.0 pyasn1-modules-0.3.0 requests-2.31.0 requests-oauthlib-1.3.1 rsa-4.9 six-1.16.0 tensorboard-2.8.0 tensorboard-data-server-0.6.1 tensorboard-plugin-wit-1.8.1 urllib3-1.26.16 werkzeug-2.3.6 zipp-3.15.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "six"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow==2.8.0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ognb7wr8LEw9",
        "outputId": "b1da04cd-ed1b-4c2b-eecf-f3e41af3b063"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting tensorflow==2.8.0\n",
            "  Downloading tensorflow-2.8.0-cp38-cp38-manylinux2010_x86_64.whl (497.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 497.6 MB 1.6 kB/s \n",
            "\u001b[?25hRequirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.8.0) (1.16.0)\n",
            "Collecting h5py>=2.9.0\n",
            "  Downloading h5py-3.8.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.7 MB 82.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: absl-py>=0.4.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.8.0) (1.4.0)\n",
            "Collecting libclang>=9.0.1\n",
            "  Downloading libclang-16.0.0-py2.py3-none-manylinux2010_x86_64.whl (22.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 22.9 MB 1.2 MB/s \n",
            "\u001b[?25hCollecting gast>=0.2.1\n",
            "  Downloading gast-0.5.4-py3-none-any.whl (19 kB)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.8.0) (1.23.0)\n",
            "Collecting google-pasta>=0.1.1\n",
            "  Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
            "\u001b[K     |████████████████████████████████| 57 kB 4.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: keras<2.9,>=2.8.0rc0 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.8.0) (2.8.0rc0)\n",
            "Collecting wrapt>=1.11.0\n",
            "  Downloading wrapt-1.15.0-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (81 kB)\n",
            "\u001b[K     |████████████████████████████████| 81 kB 9.5 MB/s \n",
            "\u001b[?25hCollecting typing-extensions>=3.6.6\n",
            "  Downloading typing_extensions-4.6.3-py3-none-any.whl (31 kB)\n",
            "Collecting flatbuffers>=1.12\n",
            "  Downloading flatbuffers-23.5.26-py2.py3-none-any.whl (26 kB)\n",
            "Collecting termcolor>=1.1.0\n",
            "  Downloading termcolor-2.3.0-py3-none-any.whl (6.9 kB)\n",
            "Collecting astunparse>=1.6.0\n",
            "  Downloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.8.0) (4.23.3)\n",
            "Requirement already satisfied: tensorboard<2.9,>=2.8 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.8.0) (2.8.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.8.0) (1.54.2)\n",
            "Collecting opt-einsum>=2.3.2\n",
            "  Downloading opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
            "\u001b[K     |████████████████████████████████| 65 kB 3.4 MB/s \n",
            "\u001b[?25hCollecting tf-estimator-nightly==2.8.0.dev2021122109\n",
            "  Downloading tf_estimator_nightly-2.8.0.dev2021122109-py2.py3-none-any.whl (462 kB)\n",
            "\u001b[K     |████████████████████████████████| 462 kB 66.3 MB/s \n",
            "\u001b[?25hCollecting keras-preprocessing>=1.1.1\n",
            "  Downloading Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)\n",
            "\u001b[K     |████████████████████████████████| 42 kB 1.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: setuptools in /usr/lib/python3/dist-packages (from tensorflow==2.8.0) (45.2.0)\n",
            "Collecting tensorflow-io-gcs-filesystem>=0.23.1\n",
            "  Downloading tensorflow_io_gcs_filesystem-0.32.0-cp38-cp38-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (2.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.4 MB 56.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: wheel<1.0,>=0.23.0 in /usr/lib/python3/dist-packages (from astunparse>=1.6.0->tensorflow==2.8.0) (0.34.2)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.9,>=2.8->tensorflow==2.8.0) (3.4.3)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.9,>=2.8->tensorflow==2.8.0) (0.6.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.9,>=2.8->tensorflow==2.8.0) (2.31.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.9,>=2.8->tensorflow==2.8.0) (0.4.6)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.9,>=2.8->tensorflow==2.8.0) (1.8.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.9,>=2.8->tensorflow==2.8.0) (2.3.6)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.9,>=2.8->tensorflow==2.8.0) (2.20.0)\n",
            "Requirement already satisfied: importlib-metadata>=4.4; python_version < \"3.10\" in /usr/local/lib/python3.8/dist-packages (from markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow==2.8.0) (6.6.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow==2.8.0) (3.1.0)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow==2.8.0) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow==2.8.0) (2023.5.7)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow==2.8.0) (3.4)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.8/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow==2.8.0) (1.3.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.8/dist-packages (from werkzeug>=0.11.15->tensorboard<2.9,>=2.8->tensorflow==2.8.0) (2.1.3)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow==2.8.0) (0.3.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow==2.8.0) (5.3.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow==2.8.0) (4.9)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.8/dist-packages (from importlib-metadata>=4.4; python_version < \"3.10\"->markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow==2.8.0) (3.15.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.8/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow==2.8.0) (3.2.2)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.8/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow==2.8.0) (0.5.0)\n",
            "Installing collected packages: h5py, libclang, gast, google-pasta, wrapt, typing-extensions, flatbuffers, termcolor, astunparse, opt-einsum, tf-estimator-nightly, keras-preprocessing, tensorflow-io-gcs-filesystem, tensorflow\n",
            "Successfully installed astunparse-1.6.3 flatbuffers-23.5.26 gast-0.5.4 google-pasta-0.2.0 h5py-3.8.0 keras-preprocessing-1.1.2 libclang-16.0.0 opt-einsum-3.3.0 tensorflow-2.8.0 tensorflow-io-gcs-filesystem-0.32.0 termcolor-2.3.0 tf-estimator-nightly-2.8.0.dev2021122109 typing-extensions-4.6.3 wrapt-1.15.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade protobuf==4.21.6"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VNh9hjEVLKyI",
        "outputId": "c844ac42-b93a-4861-fe81-55cb155c45bb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting protobuf==4.21.6\n",
            "  Downloading protobuf-4.21.6-cp37-abi3-manylinux2014_x86_64.whl (408 kB)\n",
            "\u001b[K     |████████████████████████████████| 408 kB 10.4 MB/s \n",
            "\u001b[?25hInstalling collected packages: protobuf\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 4.23.3\n",
            "    Uninstalling protobuf-4.23.3:\n",
            "      Successfully uninstalled protobuf-4.23.3\n",
            "Successfully installed protobuf-4.21.6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6cv3K3oaksJv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "02dfd683-482f-45a0-a561-237bd0b66c10"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following NEW packages will be installed:\n",
            "  libportaudio2\n",
            "0 upgraded, 1 newly installed, 0 to remove and 15 not upgraded.\n",
            "Need to get 65.4 kB of archives.\n",
            "After this operation, 223 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu focal/universe amd64 libportaudio2 amd64 19.6.0-1build1 [65.4 kB]\n",
            "Fetched 65.4 kB in 0s (895 kB/s)\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 76, <> line 1.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "Selecting previously unselected package libportaudio2:amd64.\n",
            "(Reading database ... 123433 files and directories currently installed.)\n",
            "Preparing to unpack .../libportaudio2_19.6.0-1build1_amd64.deb ...\n",
            "Unpacking libportaudio2:amd64 (19.6.0-1build1) ...\n",
            "Setting up libportaudio2:amd64 (19.6.0-1build1) ...\n",
            "Processing triggers for libc-bin (2.31-0ubuntu9.9) ...\n"
          ]
        }
      ],
      "source": [
        "!sudo apt -y install libportaudio2"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tflite-model-maker"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "b8-DY3HGdfh3",
        "outputId": "bd068d06-8795-4ffd-d16c-22e0d35ecf04"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting tflite-model-maker\n",
            "  Downloading tflite_model_maker-0.4.2-py3-none-any.whl (577 kB)\n",
            "\u001b[K     |████████████████████████████████| 577 kB 14.7 MB/s \n",
            "\u001b[?25hCollecting tflite-support>=0.4.2\n",
            "  Downloading tflite_support-0.4.3-cp38-cp38-manylinux2014_x86_64.whl (60.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 60.8 MB 1.2 MB/s \n",
            "\u001b[?25hCollecting neural-structured-learning>=1.3.1\n",
            "  Downloading neural_structured_learning-1.4.0-py2.py3-none-any.whl (128 kB)\n",
            "\u001b[K     |████████████████████████████████| 128 kB 63.1 MB/s \n",
            "\u001b[?25hCollecting tensorflow-model-optimization>=0.5\n",
            "  Downloading tensorflow_model_optimization-0.7.5-py2.py3-none-any.whl (241 kB)\n",
            "\u001b[K     |████████████████████████████████| 241 kB 62.7 MB/s \n",
            "\u001b[?25hCollecting scann==1.2.6\n",
            "  Downloading scann-1.2.6-cp38-cp38-manylinux2014_x86_64.whl (10.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 10.9 MB 55.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.8/dist-packages (from tflite-model-maker) (1.23.0)\n",
            "Collecting urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1\n",
            "  Downloading urllib3-1.25.11-py2.py3-none-any.whl (127 kB)\n",
            "\u001b[K     |████████████████████████████████| 127 kB 53.3 MB/s \n",
            "\u001b[?25hCollecting librosa==0.8.1\n",
            "  Downloading librosa-0.8.1-py3-none-any.whl (203 kB)\n",
            "\u001b[K     |████████████████████████████████| 203 kB 64.1 MB/s \n",
            "\u001b[?25hCollecting matplotlib<3.5.0,>=3.0.3\n",
            "  Downloading matplotlib-3.4.3-cp38-cp38-manylinux1_x86_64.whl (10.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 10.3 MB 62.2 MB/s \n",
            "\u001b[?25hCollecting Cython>=0.29.13\n",
            "  Downloading Cython-0.29.35-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_24_x86_64.whl (2.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.0 MB 48.4 MB/s \n",
            "\u001b[?25hCollecting tensorflow-addons>=0.11.2\n",
            "  Downloading tensorflow_addons-0.20.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (591 kB)\n",
            "\u001b[K     |████████████████████████████████| 591 kB 65.0 MB/s \n",
            "\u001b[?25hCollecting tf-models-official==2.3.0\n",
            "  Downloading tf_models_official-2.3.0-py2.py3-none-any.whl (840 kB)\n",
            "\u001b[K     |████████████████████████████████| 840 kB 52.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.8/dist-packages (from tflite-model-maker) (1.16.0)\n",
            "Collecting pillow>=7.0.0\n",
            "  Downloading Pillow-9.5.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.3 MB 63.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.8/dist-packages (from tflite-model-maker) (23.5.26)\n",
            "Collecting tensorflowjs<3.19.0,>=2.4.0\n",
            "  Downloading tensorflowjs-3.18.0-py3-none-any.whl (77 kB)\n",
            "\u001b[K     |████████████████████████████████| 77 kB 195 kB/s \n",
            "\u001b[?25hCollecting lxml>=4.6.1\n",
            "  Downloading lxml-4.9.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_24_x86_64.whl (7.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 7.1 MB 54.4 MB/s \n",
            "\u001b[?25hCollecting fire>=0.3.1\n",
            "  Downloading fire-0.5.0.tar.gz (88 kB)\n",
            "\u001b[K     |████████████████████████████████| 88 kB 7.6 MB/s \n",
            "\u001b[?25hCollecting tensorflow-hub<0.13,>=0.7.0; python_version >= \"3\"\n",
            "  Downloading tensorflow_hub-0.12.0-py2.py3-none-any.whl (108 kB)\n",
            "\u001b[K     |████████████████████████████████| 108 kB 60.8 MB/s \n",
            "\u001b[?25hCollecting PyYAML>=5.1\n",
            "  Downloading PyYAML-6.0-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (701 kB)\n",
            "\u001b[K     |████████████████████████████████| 701 kB 58.5 MB/s \n",
            "\u001b[?25hCollecting tensorflow-datasets>=2.1.0\n",
            "  Downloading tensorflow_datasets-4.9.2-py3-none-any.whl (5.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 5.4 MB 65.0 MB/s \n",
            "\u001b[?25hCollecting numba==0.53\n",
            "  Downloading numba-0.53.0-cp38-cp38-manylinux2014_x86_64.whl (3.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.4 MB 62.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: absl-py>=0.10.0 in /usr/local/lib/python3.8/dist-packages (from tflite-model-maker) (1.4.0)\n",
            "Collecting sentencepiece>=0.1.91\n",
            "  Downloading sentencepiece-0.1.99-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.3 MB 62.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tensorflow>=2.6.0 in /usr/local/lib/python3.8/dist-packages (from tflite-model-maker) (2.8.0)\n",
            "Collecting sounddevice>=0.4.4\n",
            "  Downloading sounddevice-0.4.6-py3-none-any.whl (31 kB)\n",
            "Collecting pybind11>=2.6.0\n",
            "  Downloading pybind11-2.10.4-py3-none-any.whl (222 kB)\n",
            "\u001b[K     |████████████████████████████████| 222 kB 65.0 MB/s \n",
            "\u001b[?25hCollecting protobuf<4,>=3.18.0\n",
            "  Downloading protobuf-3.20.3-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.whl (1.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.0 MB 55.9 MB/s \n",
            "\u001b[?25hCollecting scipy\n",
            "  Downloading scipy-1.10.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (34.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 34.5 MB 39 kB/s \n",
            "\u001b[?25hCollecting attrs\n",
            "  Downloading attrs-23.1.0-py3-none-any.whl (61 kB)\n",
            "\u001b[K     |████████████████████████████████| 61 kB 5.7 MB/s \n",
            "\u001b[?25hCollecting dm-tree~=0.1.1\n",
            "  Downloading dm_tree-0.1.8-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (152 kB)\n",
            "\u001b[K     |████████████████████████████████| 152 kB 72.0 MB/s \n",
            "\u001b[?25hCollecting soundfile>=0.10.2\n",
            "  Downloading soundfile-0.12.1-py2.py3-none-any.whl (24 kB)\n",
            "Collecting joblib>=0.14\n",
            "  Downloading joblib-1.2.0-py3-none-any.whl (297 kB)\n",
            "\u001b[K     |████████████████████████████████| 297 kB 58.0 MB/s \n",
            "\u001b[?25hCollecting scikit-learn!=0.19.0,>=0.14.0\n",
            "  Downloading scikit_learn-1.2.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (9.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 9.8 MB 2.3 MB/s \n",
            "\u001b[?25hCollecting decorator>=3.0.0\n",
            "  Downloading decorator-5.1.1-py3-none-any.whl (9.1 kB)\n",
            "Collecting audioread>=2.0.0\n",
            "  Downloading audioread-3.0.0.tar.gz (377 kB)\n",
            "\u001b[K     |████████████████████████████████| 377 kB 85.3 MB/s \n",
            "\u001b[?25hCollecting resampy>=0.2.2\n",
            "  Downloading resampy-0.4.2-py3-none-any.whl (3.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.1 MB 57.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from librosa==0.8.1->tflite-model-maker) (20.9)\n",
            "Collecting pooch>=1.0\n",
            "  Downloading pooch-1.7.0-py3-none-any.whl (60 kB)\n",
            "\u001b[K     |████████████████████████████████| 60 kB 7.9 MB/s \n",
            "\u001b[?25hCollecting python-dateutil>=2.7\n",
            "  Downloading python_dateutil-2.8.2-py2.py3-none-any.whl (247 kB)\n",
            "\u001b[K     |████████████████████████████████| 247 kB 62.3 MB/s \n",
            "\u001b[?25hCollecting kiwisolver>=1.0.1\n",
            "  Downloading kiwisolver-1.4.4-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.whl (1.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2 MB 67.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyparsing>=2.2.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib<3.5.0,>=3.0.3->tflite-model-maker) (3.0.9)\n",
            "Collecting cycler>=0.10\n",
            "  Downloading cycler-0.11.0-py3-none-any.whl (6.4 kB)\n",
            "Collecting typeguard<3.0.0,>=2.7\n",
            "  Downloading typeguard-2.13.3-py3-none-any.whl (17 kB)\n",
            "Collecting google-api-python-client>=1.6.7\n",
            "  Downloading google_api_python_client-2.89.0-py2.py3-none-any.whl (11.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 11.5 MB 54.4 MB/s \n",
            "\u001b[?25hCollecting kaggle>=1.3.9\n",
            "  Downloading kaggle-1.5.13.tar.gz (63 kB)\n",
            "\u001b[K     |████████████████████████████████| 63 kB 2.1 MB/s \n",
            "\u001b[?25hCollecting pandas>=0.22.0\n",
            "  Downloading pandas-2.0.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 12.3 MB 55.9 MB/s \n",
            "\u001b[?25hCollecting py-cpuinfo>=3.3.0\n",
            "  Downloading py_cpuinfo-9.0.0-py3-none-any.whl (22 kB)\n",
            "Collecting psutil>=5.4.3\n",
            "  Downloading psutil-5.9.5-cp36-abi3-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (282 kB)\n",
            "\u001b[K     |████████████████████████████████| 282 kB 69.5 MB/s \n",
            "\u001b[?25hCollecting google-cloud-bigquery>=0.31.0\n",
            "  Downloading google_cloud_bigquery-3.11.1-py2.py3-none-any.whl (219 kB)\n",
            "\u001b[K     |████████████████████████████████| 219 kB 66.3 MB/s \n",
            "\u001b[?25hCollecting opencv-python-headless\n",
            "  Downloading opencv_python_headless-4.7.0.72-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (49.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 49.2 MB 167 kB/s \n",
            "\u001b[?25hCollecting gin-config\n",
            "  Downloading gin_config-0.5.0-py3-none-any.whl (61 kB)\n",
            "\u001b[K     |████████████████████████████████| 61 kB 7.0 MB/s \n",
            "\u001b[?25hCollecting tf-slim>=1.1.0\n",
            "  Downloading tf_slim-1.1.0-py2.py3-none-any.whl (352 kB)\n",
            "\u001b[K     |████████████████████████████████| 352 kB 47.9 MB/s \n",
            "\u001b[?25hCollecting dataclasses\n",
            "  Downloading dataclasses-0.6-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.8/dist-packages (from fire>=0.3.1->tflite-model-maker) (2.3.0)\n",
            "Collecting promise\n",
            "  Downloading promise-2.3.tar.gz (19 kB)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.8/dist-packages (from tensorflow-datasets>=2.1.0->tflite-model-maker) (1.15.0)\n",
            "Collecting click\n",
            "  Downloading click-8.1.3-py3-none-any.whl (96 kB)\n",
            "\u001b[K     |████████████████████████████████| 96 kB 4.8 MB/s \n",
            "\u001b[?25hCollecting tqdm\n",
            "  Downloading tqdm-4.65.0-py3-none-any.whl (77 kB)\n",
            "\u001b[K     |████████████████████████████████| 77 kB 4.8 MB/s \n",
            "\u001b[?25hCollecting toml\n",
            "  Downloading toml-0.10.2-py2.py3-none-any.whl (16 kB)\n",
            "Collecting array-record\n",
            "  Downloading array_record-0.2.0-py38-none-any.whl (3.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.0 MB 47.2 MB/s \n",
            "\u001b[?25hCollecting etils[enp,epath]>=0.9.0\n",
            "  Downloading etils-1.3.0-py3-none-any.whl (126 kB)\n",
            "\u001b[K     |████████████████████████████████| 126 kB 54.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow-datasets>=2.1.0->tflite-model-maker) (2.31.0)\n",
            "Collecting importlib-resources; python_version < \"3.9\"\n",
            "  Downloading importlib_resources-5.12.0-py3-none-any.whl (36 kB)\n",
            "Collecting tensorflow-metadata\n",
            "  Downloading tensorflow_metadata-1.13.1-py3-none-any.whl (28 kB)\n",
            "Collecting llvmlite<0.37,>=0.36.0rc1\n",
            "  Downloading llvmlite-0.36.0-cp38-cp38-manylinux2010_x86_64.whl (25.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 25.3 MB 1.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: setuptools in /usr/lib/python3/dist-packages (from numba==0.53->tflite-model-maker) (45.2.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.6.0->tflite-model-maker) (1.54.2)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.6.0->tflite-model-maker) (1.1.2)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.6.0->tflite-model-maker) (0.32.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.6.0->tflite-model-maker) (1.6.3)\n",
            "Requirement already satisfied: gast>=0.2.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.6.0->tflite-model-maker) (0.5.4)\n",
            "Requirement already satisfied: tensorboard<2.9,>=2.8 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.6.0->tflite-model-maker) (2.8.0)\n",
            "Requirement already satisfied: tf-estimator-nightly==2.8.0.dev2021122109 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.6.0->tflite-model-maker) (2.8.0.dev2021122109)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.6.0->tflite-model-maker) (4.6.3)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.6.0->tflite-model-maker) (3.8.0)\n",
            "Requirement already satisfied: libclang>=9.0.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.6.0->tflite-model-maker) (16.0.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.6.0->tflite-model-maker) (3.3.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.6.0->tflite-model-maker) (0.2.0)\n",
            "Requirement already satisfied: keras<2.9,>=2.8.0rc0 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.6.0->tflite-model-maker) (2.8.0rc0)\n",
            "Collecting CFFI>=1.0\n",
            "  Downloading cffi-1.15.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (442 kB)\n",
            "\u001b[K     |████████████████████████████████| 442 kB 79.0 MB/s \n",
            "\u001b[?25hCollecting threadpoolctl>=2.0.0\n",
            "  Downloading threadpoolctl-3.1.0-py3-none-any.whl (14 kB)\n",
            "Collecting platformdirs>=2.5.0\n",
            "  Downloading platformdirs-3.6.0-py3-none-any.whl (16 kB)\n",
            "Requirement already satisfied: google-auth<3.0.0.dev0,>=1.19.0 in /usr/local/lib/python3.8/dist-packages (from google-api-python-client>=1.6.7->tf-models-official==2.3.0->tflite-model-maker) (2.20.0)\n",
            "Collecting google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5\n",
            "  Downloading google_api_core-2.11.1-py3-none-any.whl (120 kB)\n",
            "\u001b[K     |████████████████████████████████| 120 kB 84.6 MB/s \n",
            "\u001b[?25hCollecting uritemplate<5,>=3.0.1\n",
            "  Downloading uritemplate-4.1.1-py2.py3-none-any.whl (10 kB)\n",
            "Collecting httplib2<1.dev0,>=0.15.0\n",
            "  Downloading httplib2-0.22.0-py3-none-any.whl (96 kB)\n",
            "\u001b[K     |████████████████████████████████| 96 kB 6.7 MB/s \n",
            "\u001b[?25hCollecting google-auth-httplib2>=0.1.0\n",
            "  Downloading google_auth_httplib2-0.1.0-py2.py3-none-any.whl (9.3 kB)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.8/dist-packages (from kaggle>=1.3.9->tf-models-official==2.3.0->tflite-model-maker) (2023.5.7)\n",
            "Collecting python-slugify\n",
            "  Downloading python_slugify-8.0.1-py2.py3-none-any.whl (9.7 kB)\n",
            "Collecting pytz>=2020.1\n",
            "  Downloading pytz-2023.3-py2.py3-none-any.whl (502 kB)\n",
            "\u001b[K     |████████████████████████████████| 502 kB 62.3 MB/s \n",
            "\u001b[?25hCollecting tzdata>=2022.1\n",
            "  Downloading tzdata-2023.3-py2.py3-none-any.whl (341 kB)\n",
            "\u001b[K     |████████████████████████████████| 341 kB 85.5 MB/s \n",
            "\u001b[?25hCollecting google-cloud-core<3.0.0dev,>=1.6.0\n",
            "  Downloading google_cloud_core-2.3.2-py2.py3-none-any.whl (29 kB)\n",
            "Collecting proto-plus<2.0.0dev,>=1.15.0\n",
            "  Downloading proto_plus-1.22.2-py3-none-any.whl (47 kB)\n",
            "\u001b[K     |████████████████████████████████| 47 kB 5.5 MB/s \n",
            "\u001b[?25hCollecting google-resumable-media<3.0dev,>=0.6.0\n",
            "  Downloading google_resumable_media-2.5.0-py2.py3-none-any.whl (77 kB)\n",
            "\u001b[K     |████████████████████████████████| 77 kB 7.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: zipp; extra == \"epath\" in /usr/local/lib/python3.8/dist-packages (from etils[enp,epath]>=0.9.0->tensorflow-datasets>=2.1.0->tflite-model-maker) (3.15.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->tensorflow-datasets>=2.1.0->tflite-model-maker) (3.1.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->tensorflow-datasets>=2.1.0->tflite-model-maker) (3.4)\n",
            "Collecting googleapis-common-protos<2,>=1.52.0\n",
            "  Downloading googleapis_common_protos-1.59.1-py2.py3-none-any.whl (224 kB)\n",
            "\u001b[K     |████████████████████████████████| 224 kB 65.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: wheel<1.0,>=0.23.0 in /usr/lib/python3/dist-packages (from astunparse>=1.6.0->tensorflow>=2.6.0->tflite-model-maker) (0.34.2)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.9,>=2.8->tensorflow>=2.6.0->tflite-model-maker) (0.6.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.9,>=2.8->tensorflow>=2.6.0->tflite-model-maker) (2.3.6)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.9,>=2.8->tensorflow>=2.6.0->tflite-model-maker) (0.4.6)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.9,>=2.8->tensorflow>=2.6.0->tflite-model-maker) (1.8.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.9,>=2.8->tensorflow>=2.6.0->tflite-model-maker) (3.4.3)\n",
            "Collecting pycparser\n",
            "  Downloading pycparser-2.21-py2.py3-none-any.whl (118 kB)\n",
            "\u001b[K     |████████████████████████████████| 118 kB 66.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from google-auth<3.0.0.dev0,>=1.19.0->google-api-python-client>=1.6.7->tf-models-official==2.3.0->tflite-model-maker) (5.3.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.8/dist-packages (from google-auth<3.0.0.dev0,>=1.19.0->google-api-python-client>=1.6.7->tf-models-official==2.3.0->tflite-model-maker) (4.9)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.8/dist-packages (from google-auth<3.0.0.dev0,>=1.19.0->google-api-python-client>=1.6.7->tf-models-official==2.3.0->tflite-model-maker) (0.3.0)\n",
            "Collecting text-unidecode>=1.3\n",
            "  Downloading text_unidecode-1.3-py2.py3-none-any.whl (78 kB)\n",
            "\u001b[K     |████████████████████████████████| 78 kB 4.8 MB/s \n",
            "\u001b[?25hCollecting google-crc32c<2.0dev,>=1.0\n",
            "  Downloading google_crc32c-1.5.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (32 kB)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.8/dist-packages (from werkzeug>=0.11.15->tensorboard<2.9,>=2.8->tensorflow>=2.6.0->tflite-model-maker) (2.1.3)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.8/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow>=2.6.0->tflite-model-maker) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4; python_version < \"3.10\" in /usr/local/lib/python3.8/dist-packages (from markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow>=2.6.0->tflite-model-maker) (6.6.0)\n",
            "Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.8/dist-packages (from rsa<5,>=3.1.4->google-auth<3.0.0.dev0,>=1.19.0->google-api-python-client>=1.6.7->tf-models-official==2.3.0->tflite-model-maker) (0.5.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.8/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow>=2.6.0->tflite-model-maker) (3.2.2)\n",
            "Building wheels for collected packages: fire, audioread, kaggle, promise\n",
            "  Building wheel for fire (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fire: filename=fire-0.5.0-py2.py3-none-any.whl size=116936 sha256=5d03f2f9acbf641cd0a7fbb9de03626b43693265fb42fc90110962840eaf3bfc\n",
            "  Stored in directory: /root/.cache/pip/wheels/5b/eb/43/7295e71293b218ddfd627f935229bf54af9018add7fbb5aac6\n",
            "  Building wheel for audioread (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for audioread: filename=audioread-3.0.0-py3-none-any.whl size=23692 sha256=6415b0c7c6246f18d4c715fedc5d01c896c882eb55e0e7e9c3044bc5c5d3f623\n",
            "  Stored in directory: /root/.cache/pip/wheels/0a/ed/be/49df2538fca496690a024a4374455584d65c2afd6fc3d6e9c7\n",
            "  Building wheel for kaggle (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for kaggle: filename=kaggle-1.5.13-py3-none-any.whl size=77720 sha256=5f3982d2747aab31d0c04a5c498767211d02e724208906b74f646b19719d9bf5\n",
            "  Stored in directory: /root/.cache/pip/wheels/e6/8e/67/e07554a720a493dc6b39b30488590ba92ed45448ad0134d253\n",
            "  Building wheel for promise (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for promise: filename=promise-2.3-py3-none-any.whl size=21493 sha256=4cffacc1e35385c584c4c08f5642e4d3bf0932d5ddd4126c06fe7a4a8a779460\n",
            "  Stored in directory: /root/.cache/pip/wheels/54/aa/01/724885182f93150035a2a91bce34a12877e8067a97baaf5dc8\n",
            "Successfully built fire audioread kaggle promise\n",
            "Installing collected packages: pycparser, CFFI, sounddevice, pybind11, protobuf, tflite-support, scipy, attrs, neural-structured-learning, dm-tree, tensorflow-model-optimization, scann, urllib3, soundfile, joblib, threadpoolctl, scikit-learn, decorator, audioread, llvmlite, numba, resampy, platformdirs, pooch, librosa, python-dateutil, pillow, kiwisolver, cycler, matplotlib, Cython, typeguard, tensorflow-addons, googleapis-common-protos, google-api-core, uritemplate, httplib2, google-auth-httplib2, google-api-python-client, text-unidecode, python-slugify, tqdm, kaggle, pytz, tzdata, pandas, sentencepiece, py-cpuinfo, psutil, PyYAML, google-cloud-core, proto-plus, google-crc32c, google-resumable-media, google-cloud-bigquery, promise, click, toml, importlib-resources, etils, array-record, tensorflow-metadata, tensorflow-datasets, opencv-python-headless, gin-config, tf-slim, dataclasses, tensorflow-hub, tf-models-official, tensorflowjs, lxml, fire, tflite-model-maker\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 4.21.6\n",
            "    Uninstalling protobuf-4.21.6:\n",
            "      Successfully uninstalled protobuf-4.21.6\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 1.26.16\n",
            "    Uninstalling urllib3-1.26.16:\n",
            "      Successfully uninstalled urllib3-1.26.16\n",
            "Successfully installed CFFI-1.15.1 Cython-0.29.35 PyYAML-6.0 array-record-0.2.0 attrs-23.1.0 audioread-3.0.0 click-8.1.3 cycler-0.11.0 dataclasses-0.6 decorator-5.1.1 dm-tree-0.1.8 etils-1.3.0 fire-0.5.0 gin-config-0.5.0 google-api-core-2.11.1 google-api-python-client-2.89.0 google-auth-httplib2-0.1.0 google-cloud-bigquery-3.11.1 google-cloud-core-2.3.2 google-crc32c-1.5.0 google-resumable-media-2.5.0 googleapis-common-protos-1.59.1 httplib2-0.22.0 importlib-resources-5.12.0 joblib-1.2.0 kaggle-1.5.13 kiwisolver-1.4.4 librosa-0.8.1 llvmlite-0.36.0 lxml-4.9.2 matplotlib-3.4.3 neural-structured-learning-1.4.0 numba-0.53.0 opencv-python-headless-4.7.0.72 pandas-2.0.2 pillow-9.5.0 platformdirs-3.6.0 pooch-1.7.0 promise-2.3 proto-plus-1.22.2 protobuf-3.20.3 psutil-5.9.5 py-cpuinfo-9.0.0 pybind11-2.10.4 pycparser-2.21 python-dateutil-2.8.2 python-slugify-8.0.1 pytz-2023.3 resampy-0.4.2 scann-1.2.6 scikit-learn-1.2.2 scipy-1.10.1 sentencepiece-0.1.99 sounddevice-0.4.6 soundfile-0.12.1 tensorflow-addons-0.20.0 tensorflow-datasets-4.9.2 tensorflow-hub-0.12.0 tensorflow-metadata-1.13.1 tensorflow-model-optimization-0.7.5 tensorflowjs-3.18.0 text-unidecode-1.3 tf-models-official-2.3.0 tf-slim-1.1.0 tflite-model-maker-0.4.2 tflite-support-0.4.3 threadpoolctl-3.1.0 toml-0.10.2 tqdm-4.65.0 typeguard-2.13.3 tzdata-2023.3 uritemplate-4.1.1 urllib3-1.25.11\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "cffi",
                  "cycler",
                  "dateutil",
                  "google",
                  "kiwisolver",
                  "psutil"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade tflite-model-maker"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EiPlfghfd-eV",
        "outputId": "805bda95-1032-48fe-bc75-3194e30e424c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already up-to-date: tflite-model-maker in /usr/local/lib/python3.8/dist-packages (0.4.2)\n",
            "Requirement already satisfied, skipping upgrade: neural-structured-learning>=1.3.1 in /usr/local/lib/python3.8/dist-packages (from tflite-model-maker) (1.4.0)\n",
            "Requirement already satisfied, skipping upgrade: sentencepiece>=0.1.91 in /usr/local/lib/python3.8/dist-packages (from tflite-model-maker) (0.1.99)\n",
            "Requirement already satisfied, skipping upgrade: scann==1.2.6 in /usr/local/lib/python3.8/dist-packages (from tflite-model-maker) (1.2.6)\n",
            "Requirement already satisfied, skipping upgrade: numpy>=1.17.3 in /usr/local/lib/python3.8/dist-packages (from tflite-model-maker) (1.23.0)\n",
            "Requirement already satisfied, skipping upgrade: six>=1.12.0 in /usr/local/lib/python3.8/dist-packages (from tflite-model-maker) (1.16.0)\n",
            "Requirement already satisfied, skipping upgrade: flatbuffers>=2.0 in /usr/local/lib/python3.8/dist-packages (from tflite-model-maker) (23.5.26)\n",
            "Requirement already satisfied, skipping upgrade: tensorflowjs<3.19.0,>=2.4.0 in /usr/local/lib/python3.8/dist-packages (from tflite-model-maker) (3.18.0)\n",
            "Requirement already satisfied, skipping upgrade: librosa==0.8.1 in /usr/local/lib/python3.8/dist-packages (from tflite-model-maker) (0.8.1)\n",
            "Requirement already satisfied, skipping upgrade: tensorflow-hub<0.13,>=0.7.0; python_version >= \"3\" in /usr/local/lib/python3.8/dist-packages (from tflite-model-maker) (0.12.0)\n",
            "Requirement already satisfied, skipping upgrade: pillow>=7.0.0 in /usr/local/lib/python3.8/dist-packages (from tflite-model-maker) (9.5.0)\n",
            "Requirement already satisfied, skipping upgrade: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from tflite-model-maker) (1.25.11)\n",
            "Requirement already satisfied, skipping upgrade: tf-models-official==2.3.0 in /usr/local/lib/python3.8/dist-packages (from tflite-model-maker) (2.3.0)\n",
            "Requirement already satisfied, skipping upgrade: tensorflow-model-optimization>=0.5 in /usr/local/lib/python3.8/dist-packages (from tflite-model-maker) (0.7.5)\n",
            "Requirement already satisfied, skipping upgrade: Cython>=0.29.13 in /usr/local/lib/python3.8/dist-packages (from tflite-model-maker) (0.29.35)\n",
            "Requirement already satisfied, skipping upgrade: tensorflow-datasets>=2.1.0 in /usr/local/lib/python3.8/dist-packages (from tflite-model-maker) (4.9.2)\n",
            "Requirement already satisfied, skipping upgrade: tflite-support>=0.4.2 in /usr/local/lib/python3.8/dist-packages (from tflite-model-maker) (0.4.3)\n",
            "Requirement already satisfied, skipping upgrade: numba==0.53 in /usr/local/lib/python3.8/dist-packages (from tflite-model-maker) (0.53.0)\n",
            "Requirement already satisfied, skipping upgrade: tensorflow>=2.6.0 in /usr/local/lib/python3.8/dist-packages (from tflite-model-maker) (2.8.0)\n",
            "Requirement already satisfied, skipping upgrade: matplotlib<3.5.0,>=3.0.3 in /usr/local/lib/python3.8/dist-packages (from tflite-model-maker) (3.4.3)\n",
            "Requirement already satisfied, skipping upgrade: tensorflow-addons>=0.11.2 in /usr/local/lib/python3.8/dist-packages (from tflite-model-maker) (0.20.0)\n",
            "Requirement already satisfied, skipping upgrade: PyYAML>=5.1 in /usr/local/lib/python3.8/dist-packages (from tflite-model-maker) (6.0)\n",
            "Requirement already satisfied, skipping upgrade: fire>=0.3.1 in /usr/local/lib/python3.8/dist-packages (from tflite-model-maker) (0.5.0)\n",
            "Requirement already satisfied, skipping upgrade: absl-py>=0.10.0 in /usr/local/lib/python3.8/dist-packages (from tflite-model-maker) (1.4.0)\n",
            "Requirement already satisfied, skipping upgrade: lxml>=4.6.1 in /usr/local/lib/python3.8/dist-packages (from tflite-model-maker) (4.9.2)\n",
            "Requirement already satisfied, skipping upgrade: attrs in /usr/local/lib/python3.8/dist-packages (from neural-structured-learning>=1.3.1->tflite-model-maker) (23.1.0)\n",
            "Requirement already satisfied, skipping upgrade: scipy in /usr/local/lib/python3.8/dist-packages (from neural-structured-learning>=1.3.1->tflite-model-maker) (1.10.1)\n",
            "Requirement already satisfied, skipping upgrade: packaging~=20.9 in /usr/local/lib/python3.8/dist-packages (from tensorflowjs<3.19.0,>=2.4.0->tflite-model-maker) (20.9)\n",
            "Requirement already satisfied, skipping upgrade: resampy>=0.2.2 in /usr/local/lib/python3.8/dist-packages (from librosa==0.8.1->tflite-model-maker) (0.4.2)\n",
            "Requirement already satisfied, skipping upgrade: pooch>=1.0 in /usr/local/lib/python3.8/dist-packages (from librosa==0.8.1->tflite-model-maker) (1.7.0)\n",
            "Requirement already satisfied, skipping upgrade: decorator>=3.0.0 in /usr/local/lib/python3.8/dist-packages (from librosa==0.8.1->tflite-model-maker) (5.1.1)\n",
            "Requirement already satisfied, skipping upgrade: audioread>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from librosa==0.8.1->tflite-model-maker) (3.0.0)\n",
            "Requirement already satisfied, skipping upgrade: soundfile>=0.10.2 in /usr/local/lib/python3.8/dist-packages (from librosa==0.8.1->tflite-model-maker) (0.12.1)\n",
            "Requirement already satisfied, skipping upgrade: joblib>=0.14 in /usr/local/lib/python3.8/dist-packages (from librosa==0.8.1->tflite-model-maker) (1.2.0)\n",
            "Requirement already satisfied, skipping upgrade: scikit-learn!=0.19.0,>=0.14.0 in /usr/local/lib/python3.8/dist-packages (from librosa==0.8.1->tflite-model-maker) (1.2.2)\n",
            "Requirement already satisfied, skipping upgrade: protobuf>=3.8.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow-hub<0.13,>=0.7.0; python_version >= \"3\"->tflite-model-maker) (3.20.3)\n",
            "Requirement already satisfied, skipping upgrade: opencv-python-headless in /usr/local/lib/python3.8/dist-packages (from tf-models-official==2.3.0->tflite-model-maker) (4.7.0.72)\n",
            "Requirement already satisfied, skipping upgrade: py-cpuinfo>=3.3.0 in /usr/local/lib/python3.8/dist-packages (from tf-models-official==2.3.0->tflite-model-maker) (9.0.0)\n",
            "Requirement already satisfied, skipping upgrade: psutil>=5.4.3 in /usr/local/lib/python3.8/dist-packages (from tf-models-official==2.3.0->tflite-model-maker) (5.9.5)\n",
            "Requirement already satisfied, skipping upgrade: tf-slim>=1.1.0 in /usr/local/lib/python3.8/dist-packages (from tf-models-official==2.3.0->tflite-model-maker) (1.1.0)\n",
            "Requirement already satisfied, skipping upgrade: google-api-python-client>=1.6.7 in /usr/local/lib/python3.8/dist-packages (from tf-models-official==2.3.0->tflite-model-maker) (2.89.0)\n",
            "Requirement already satisfied, skipping upgrade: google-cloud-bigquery>=0.31.0 in /usr/local/lib/python3.8/dist-packages (from tf-models-official==2.3.0->tflite-model-maker) (3.11.1)\n",
            "Requirement already satisfied, skipping upgrade: kaggle>=1.3.9 in /usr/local/lib/python3.8/dist-packages (from tf-models-official==2.3.0->tflite-model-maker) (1.5.13)\n",
            "Requirement already satisfied, skipping upgrade: dataclasses in /usr/local/lib/python3.8/dist-packages (from tf-models-official==2.3.0->tflite-model-maker) (0.6)\n",
            "Requirement already satisfied, skipping upgrade: gin-config in /usr/local/lib/python3.8/dist-packages (from tf-models-official==2.3.0->tflite-model-maker) (0.5.0)\n",
            "Requirement already satisfied, skipping upgrade: pandas>=0.22.0 in /usr/local/lib/python3.8/dist-packages (from tf-models-official==2.3.0->tflite-model-maker) (2.0.2)\n",
            "Requirement already satisfied, skipping upgrade: dm-tree~=0.1.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow-model-optimization>=0.5->tflite-model-maker) (0.1.8)\n",
            "Requirement already satisfied, skipping upgrade: tensorflow-metadata in /usr/local/lib/python3.8/dist-packages (from tensorflow-datasets>=2.1.0->tflite-model-maker) (1.13.1)\n",
            "Requirement already satisfied, skipping upgrade: importlib-resources; python_version < \"3.9\" in /usr/local/lib/python3.8/dist-packages (from tensorflow-datasets>=2.1.0->tflite-model-maker) (5.12.0)\n",
            "Requirement already satisfied, skipping upgrade: tqdm in /usr/local/lib/python3.8/dist-packages (from tensorflow-datasets>=2.1.0->tflite-model-maker) (4.65.0)\n",
            "Requirement already satisfied, skipping upgrade: termcolor in /usr/local/lib/python3.8/dist-packages (from tensorflow-datasets>=2.1.0->tflite-model-maker) (2.3.0)\n",
            "Requirement already satisfied, skipping upgrade: click in /usr/local/lib/python3.8/dist-packages (from tensorflow-datasets>=2.1.0->tflite-model-maker) (8.1.3)\n",
            "Requirement already satisfied, skipping upgrade: requests>=2.19.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow-datasets>=2.1.0->tflite-model-maker) (2.31.0)\n",
            "Requirement already satisfied, skipping upgrade: promise in /usr/local/lib/python3.8/dist-packages (from tensorflow-datasets>=2.1.0->tflite-model-maker) (2.3)\n",
            "Requirement already satisfied, skipping upgrade: array-record in /usr/local/lib/python3.8/dist-packages (from tensorflow-datasets>=2.1.0->tflite-model-maker) (0.2.0)\n",
            "Requirement already satisfied, skipping upgrade: etils[enp,epath]>=0.9.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow-datasets>=2.1.0->tflite-model-maker) (1.3.0)\n",
            "Requirement already satisfied, skipping upgrade: wrapt in /usr/local/lib/python3.8/dist-packages (from tensorflow-datasets>=2.1.0->tflite-model-maker) (1.15.0)\n",
            "Requirement already satisfied, skipping upgrade: toml in /usr/local/lib/python3.8/dist-packages (from tensorflow-datasets>=2.1.0->tflite-model-maker) (0.10.2)\n",
            "Requirement already satisfied, skipping upgrade: sounddevice>=0.4.4 in /usr/local/lib/python3.8/dist-packages (from tflite-support>=0.4.2->tflite-model-maker) (0.4.6)\n",
            "Requirement already satisfied, skipping upgrade: pybind11>=2.6.0 in /usr/local/lib/python3.8/dist-packages (from tflite-support>=0.4.2->tflite-model-maker) (2.10.4)\n",
            "Requirement already satisfied, skipping upgrade: llvmlite<0.37,>=0.36.0rc1 in /usr/local/lib/python3.8/dist-packages (from numba==0.53->tflite-model-maker) (0.36.0)\n",
            "Requirement already satisfied, skipping upgrade: setuptools in /usr/lib/python3/dist-packages (from numba==0.53->tflite-model-maker) (45.2.0)\n",
            "Requirement already satisfied, skipping upgrade: libclang>=9.0.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.6.0->tflite-model-maker) (16.0.0)\n",
            "Requirement already satisfied, skipping upgrade: gast>=0.2.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.6.0->tflite-model-maker) (0.5.4)\n",
            "Requirement already satisfied, skipping upgrade: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.6.0->tflite-model-maker) (1.1.2)\n",
            "Requirement already satisfied, skipping upgrade: tf-estimator-nightly==2.8.0.dev2021122109 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.6.0->tflite-model-maker) (2.8.0.dev2021122109)\n",
            "Requirement already satisfied, skipping upgrade: opt-einsum>=2.3.2 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.6.0->tflite-model-maker) (3.3.0)\n",
            "Requirement already satisfied, skipping upgrade: h5py>=2.9.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.6.0->tflite-model-maker) (3.8.0)\n",
            "Requirement already satisfied, skipping upgrade: google-pasta>=0.1.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.6.0->tflite-model-maker) (0.2.0)\n",
            "Requirement already satisfied, skipping upgrade: keras<2.9,>=2.8.0rc0 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.6.0->tflite-model-maker) (2.8.0rc0)\n",
            "Requirement already satisfied, skipping upgrade: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.6.0->tflite-model-maker) (0.32.0)\n",
            "Requirement already satisfied, skipping upgrade: typing-extensions>=3.6.6 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.6.0->tflite-model-maker) (4.6.3)\n",
            "Requirement already satisfied, skipping upgrade: astunparse>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.6.0->tflite-model-maker) (1.6.3)\n",
            "Requirement already satisfied, skipping upgrade: tensorboard<2.9,>=2.8 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.6.0->tflite-model-maker) (2.8.0)\n",
            "Requirement already satisfied, skipping upgrade: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.6.0->tflite-model-maker) (1.54.2)\n",
            "Requirement already satisfied, skipping upgrade: kiwisolver>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib<3.5.0,>=3.0.3->tflite-model-maker) (1.4.4)\n",
            "Requirement already satisfied, skipping upgrade: pyparsing>=2.2.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib<3.5.0,>=3.0.3->tflite-model-maker) (3.0.9)\n",
            "Requirement already satisfied, skipping upgrade: cycler>=0.10 in /usr/local/lib/python3.8/dist-packages (from matplotlib<3.5.0,>=3.0.3->tflite-model-maker) (0.11.0)\n",
            "Requirement already satisfied, skipping upgrade: python-dateutil>=2.7 in /usr/local/lib/python3.8/dist-packages (from matplotlib<3.5.0,>=3.0.3->tflite-model-maker) (2.8.2)\n",
            "Requirement already satisfied, skipping upgrade: typeguard<3.0.0,>=2.7 in /usr/local/lib/python3.8/dist-packages (from tensorflow-addons>=0.11.2->tflite-model-maker) (2.13.3)\n",
            "Requirement already satisfied, skipping upgrade: platformdirs>=2.5.0 in /usr/local/lib/python3.8/dist-packages (from pooch>=1.0->librosa==0.8.1->tflite-model-maker) (3.6.0)\n",
            "Requirement already satisfied, skipping upgrade: cffi>=1.0 in /usr/local/lib/python3.8/dist-packages (from soundfile>=0.10.2->librosa==0.8.1->tflite-model-maker) (1.15.1)\n",
            "Requirement already satisfied, skipping upgrade: threadpoolctl>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn!=0.19.0,>=0.14.0->librosa==0.8.1->tflite-model-maker) (3.1.0)\n",
            "Requirement already satisfied, skipping upgrade: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.8/dist-packages (from google-api-python-client>=1.6.7->tf-models-official==2.3.0->tflite-model-maker) (4.1.1)\n",
            "Requirement already satisfied, skipping upgrade: google-auth<3.0.0.dev0,>=1.19.0 in /usr/local/lib/python3.8/dist-packages (from google-api-python-client>=1.6.7->tf-models-official==2.3.0->tflite-model-maker) (2.20.0)\n",
            "Requirement already satisfied, skipping upgrade: google-auth-httplib2>=0.1.0 in /usr/local/lib/python3.8/dist-packages (from google-api-python-client>=1.6.7->tf-models-official==2.3.0->tflite-model-maker) (0.1.0)\n",
            "Requirement already satisfied, skipping upgrade: httplib2<1.dev0,>=0.15.0 in /usr/local/lib/python3.8/dist-packages (from google-api-python-client>=1.6.7->tf-models-official==2.3.0->tflite-model-maker) (0.22.0)\n",
            "Requirement already satisfied, skipping upgrade: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5 in /usr/local/lib/python3.8/dist-packages (from google-api-python-client>=1.6.7->tf-models-official==2.3.0->tflite-model-maker) (2.11.1)\n",
            "Requirement already satisfied, skipping upgrade: google-cloud-core<3.0.0dev,>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from google-cloud-bigquery>=0.31.0->tf-models-official==2.3.0->tflite-model-maker) (2.3.2)\n",
            "Requirement already satisfied, skipping upgrade: google-resumable-media<3.0dev,>=0.6.0 in /usr/local/lib/python3.8/dist-packages (from google-cloud-bigquery>=0.31.0->tf-models-official==2.3.0->tflite-model-maker) (2.5.0)\n",
            "Requirement already satisfied, skipping upgrade: proto-plus<2.0.0dev,>=1.15.0 in /usr/local/lib/python3.8/dist-packages (from google-cloud-bigquery>=0.31.0->tf-models-official==2.3.0->tflite-model-maker) (1.22.2)\n",
            "Requirement already satisfied, skipping upgrade: certifi in /usr/local/lib/python3.8/dist-packages (from kaggle>=1.3.9->tf-models-official==2.3.0->tflite-model-maker) (2023.5.7)\n",
            "Requirement already satisfied, skipping upgrade: python-slugify in /usr/local/lib/python3.8/dist-packages (from kaggle>=1.3.9->tf-models-official==2.3.0->tflite-model-maker) (8.0.1)\n",
            "Requirement already satisfied, skipping upgrade: pytz>=2020.1 in /usr/local/lib/python3.8/dist-packages (from pandas>=0.22.0->tf-models-official==2.3.0->tflite-model-maker) (2023.3)\n",
            "Requirement already satisfied, skipping upgrade: tzdata>=2022.1 in /usr/local/lib/python3.8/dist-packages (from pandas>=0.22.0->tf-models-official==2.3.0->tflite-model-maker) (2023.3)\n",
            "Requirement already satisfied, skipping upgrade: googleapis-common-protos<2,>=1.52.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow-metadata->tensorflow-datasets>=2.1.0->tflite-model-maker) (1.59.1)\n",
            "Requirement already satisfied, skipping upgrade: zipp>=3.1.0; python_version < \"3.10\" in /usr/local/lib/python3.8/dist-packages (from importlib-resources; python_version < \"3.9\"->tensorflow-datasets>=2.1.0->tflite-model-maker) (3.15.0)\n",
            "Requirement already satisfied, skipping upgrade: idna<4,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->tensorflow-datasets>=2.1.0->tflite-model-maker) (3.4)\n",
            "Requirement already satisfied, skipping upgrade: charset-normalizer<4,>=2 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->tensorflow-datasets>=2.1.0->tflite-model-maker) (3.1.0)\n",
            "Requirement already satisfied, skipping upgrade: wheel<1.0,>=0.23.0 in /usr/lib/python3/dist-packages (from astunparse>=1.6.0->tensorflow>=2.6.0->tflite-model-maker) (0.34.2)\n",
            "Requirement already satisfied, skipping upgrade: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.9,>=2.8->tensorflow>=2.6.0->tflite-model-maker) (0.6.1)\n",
            "Requirement already satisfied, skipping upgrade: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.9,>=2.8->tensorflow>=2.6.0->tflite-model-maker) (1.8.1)\n",
            "Requirement already satisfied, skipping upgrade: werkzeug>=0.11.15 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.9,>=2.8->tensorflow>=2.6.0->tflite-model-maker) (2.3.6)\n",
            "Requirement already satisfied, skipping upgrade: markdown>=2.6.8 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.9,>=2.8->tensorflow>=2.6.0->tflite-model-maker) (3.4.3)\n",
            "Requirement already satisfied, skipping upgrade: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.9,>=2.8->tensorflow>=2.6.0->tflite-model-maker) (0.4.6)\n",
            "Requirement already satisfied, skipping upgrade: pycparser in /usr/local/lib/python3.8/dist-packages (from cffi>=1.0->soundfile>=0.10.2->librosa==0.8.1->tflite-model-maker) (2.21)\n",
            "Requirement already satisfied, skipping upgrade: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from google-auth<3.0.0.dev0,>=1.19.0->google-api-python-client>=1.6.7->tf-models-official==2.3.0->tflite-model-maker) (5.3.1)\n",
            "Requirement already satisfied, skipping upgrade: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.8/dist-packages (from google-auth<3.0.0.dev0,>=1.19.0->google-api-python-client>=1.6.7->tf-models-official==2.3.0->tflite-model-maker) (0.3.0)\n",
            "Requirement already satisfied, skipping upgrade: rsa<5,>=3.1.4 in /usr/local/lib/python3.8/dist-packages (from google-auth<3.0.0.dev0,>=1.19.0->google-api-python-client>=1.6.7->tf-models-official==2.3.0->tflite-model-maker) (4.9)\n",
            "Requirement already satisfied, skipping upgrade: google-crc32c<2.0dev,>=1.0 in /usr/local/lib/python3.8/dist-packages (from google-resumable-media<3.0dev,>=0.6.0->google-cloud-bigquery>=0.31.0->tf-models-official==2.3.0->tflite-model-maker) (1.5.0)\n",
            "Requirement already satisfied, skipping upgrade: text-unidecode>=1.3 in /usr/local/lib/python3.8/dist-packages (from python-slugify->kaggle>=1.3.9->tf-models-official==2.3.0->tflite-model-maker) (1.3)\n",
            "Requirement already satisfied, skipping upgrade: MarkupSafe>=2.1.1 in /usr/local/lib/python3.8/dist-packages (from werkzeug>=0.11.15->tensorboard<2.9,>=2.8->tensorflow>=2.6.0->tflite-model-maker) (2.1.3)\n",
            "Requirement already satisfied, skipping upgrade: importlib-metadata>=4.4; python_version < \"3.10\" in /usr/local/lib/python3.8/dist-packages (from markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow>=2.6.0->tflite-model-maker) (6.6.0)\n",
            "Requirement already satisfied, skipping upgrade: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.8/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow>=2.6.0->tflite-model-maker) (1.3.1)\n",
            "Requirement already satisfied, skipping upgrade: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.8/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3.0.0.dev0,>=1.19.0->google-api-python-client>=1.6.7->tf-models-official==2.3.0->tflite-model-maker) (0.5.0)\n",
            "Requirement already satisfied, skipping upgrade: oauthlib>=3.0.0 in /usr/local/lib/python3.8/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow>=2.6.0->tflite-model-maker) (3.2.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gx1HGRoFQ54j"
      },
      "source": [
        "Import the required packages."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XtxiUeZEiXpt",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        },
        "outputId": "b42978b4-ef3a-4b64-a5b2-b48804429f95"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-08d5581ca4ac>\u001b[0m in \u001b[0;36m<cell line: 8>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32massert\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__version__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'2'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtflite_model_maker\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmodel_spec\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtflite_model_maker\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mimage_classifier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtflite_model_maker\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mExportFormat\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tflite_model_maker'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "import tensorflow as tf\n",
        "assert tf.__version__.startswith('2')\n",
        "\n",
        "from tflite_model_maker import model_spec # specyfikacje predefiniowanych modeli\n",
        "from tflite_model_maker import image_classifier # funkcje i metody do tworzenia modelu klasyfikatora obrazów\n",
        "from tflite_model_maker.config import ExportFormat # definiuje formaty eksportu modelu\n",
        "from tflite_model_maker.config import QuantizationConfig # definiuje konfigurację kwantyzacji, która jest techniką kompresji modeli\n",
        "from tflite_model_maker.image_classifier import DataLoader # ładowanie danych treningowych i testowych dla modelu klasyfikatora\n",
        "\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KKRaYHABpob5"
      },
      "source": [
        "## Simple End-to-End Example"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SiZZ5DHXotaW"
      },
      "source": [
        "### Get the data path\n",
        "\n",
        "Let's get some images to play with this simple end-to-end example. Hundreds of images is a good start for Model Maker while more data could achieve better accuracy."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "3jz5x0JoskPv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ed4bec50-605f-4118-8b39-73ca4fccd0dc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/download.tensorflow.org/example_images/flower_photos.tgz\n",
            "228813984/228813984 [==============================] - 6s 0us/step\n"
          ]
        }
      ],
      "source": [
        "# image_path = tf.keras.utils.get_file(\n",
        "#       'flower_photos.tgz',\n",
        "#       'https://storage.googleapis.com/download.tensorflow.org/example_images/flower_photos.tgz',\n",
        "#       extract=True)\n",
        "image_path = 'Images'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a55MR6i6nuDm"
      },
      "source": [
        "You could replace `image_path` with your own image folders. As for uploading data to colab, you could find the upload button in the left sidebar shown in the image below with the red rectangle. Just have a try to upload a zip file and unzip it. The root file path is the current path.\n",
        "\n",
        "<img src=\"https://storage.googleapis.com/download.tensorflow.org/models/tflite/screenshots/model_maker_image_classification.png\" alt=\"Upload File\" width=\"800\" hspace=\"100\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NNRNv_mloS89"
      },
      "source": [
        "If you prefer not to upload your images to the cloud, you could try to run the library locally following the [guide](https://github.com/tensorflow/examples/tree/master/tensorflow_examples/lite/model_maker) in GitHub."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w-VDriAdsowu"
      },
      "source": [
        "### Run the example\n",
        "The example just consists of 4 lines of code as shown below, each of which representing one step of the overall process.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6ahtcO86tZBL"
      },
      "source": [
        "Step 1.   Load input data specific to an on-device ML app. Split it into training data and testing data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lANoNS_gtdH1"
      },
      "outputs": [],
      "source": [
        "image_path = os.path.join(os.getcwd(), 'POI-DNN')\n",
        "data = DataLoader.from_folder(image_path)\n",
        "train_data, rest_data = data.split(0.9)\n",
        "validation_data, test_data = rest_data.split(0.5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y_9IWyIztuRF"
      },
      "source": [
        "Step 2. Customize the TensorFlow model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yRXMZbrwtyRD"
      },
      "outputs": [],
      "source": [
        "model = image_classifier.create(train_data, validation_data = validation_data)\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oxU2fDr-t2Ya"
      },
      "source": [
        "Step 3. Evaluate the model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wQr02VxJt6Cs"
      },
      "outputs": [],
      "source": [
        "loss, accuracy = model.evaluate(test_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eVZw9zU8t84y"
      },
      "source": [
        "Step 4.  Export to TensorFlow Lite model.\n",
        "\n",
        "Here, we export TensorFlow Lite model with [metadata](https://www.tensorflow.org/lite/models/convert/metadata) which provides a standard for model descriptions. The label file is embedded in metadata. The default post-training quantization technique is full integer quantization for the image classification task.\n",
        "\n",
        "You could download it in the left sidebar same as the uploading part for your own use."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zb-eIzfluCoa"
      },
      "outputs": [],
      "source": [
        "model.export(export_dir='.')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pyju1qc_v-wy"
      },
      "source": [
        "After these simple 4 steps, we could further use TensorFlow Lite model file in on-device applications like in [image classification](https://github.com/tensorflow/examples/tree/master/lite/examples/image_classification) reference app."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R1QG32ivs9lF"
      },
      "source": [
        "## Detailed Process\n",
        "\n",
        "Currently, we support several models such as  EfficientNet-Lite* models, MobileNetV2, ResNet50 as pre-trained models for image classification. But it is very flexible to add new pre-trained models to this library with just a few lines of code.\n",
        "\n",
        "\n",
        "The following walks through this end-to-end example step by step to show more detail."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ygEncJxtl-nQ"
      },
      "source": [
        "### Step 1: Load Input Data Specific to an On-device ML App\n",
        "\n",
        "The flower dataset contains 3670 images belonging to 5 classes. Download the archive version of the dataset and untar it.\n",
        "\n",
        "The dataset has the following directory structure:\n",
        "\n",
        "<pre>\n",
        "<b>flower_photos</b>\n",
        "|__ <b>daisy</b>\n",
        "    |______ 100080576_f52e8ee070_n.jpg\n",
        "    |______ 14167534527_781ceb1b7a_n.jpg\n",
        "    |______ ...\n",
        "|__ <b>dandelion</b>\n",
        "    |______ 10043234166_e6dd915111_n.jpg\n",
        "    |______ 1426682852_e62169221f_m.jpg\n",
        "    |______ ...\n",
        "|__ <b>roses</b>\n",
        "    |______ 102501987_3cdb8e5394_n.jpg\n",
        "    |______ 14982802401_a3dfb22afb.jpg\n",
        "    |______ ...\n",
        "|__ <b>sunflowers</b>\n",
        "    |______ 12471791574_bb1be83df4.jpg\n",
        "    |______ 15122112402_cafa41934f.jpg\n",
        "    |______ ...\n",
        "|__ <b>tulips</b>\n",
        "    |______ 13976522214_ccec508fe7.jpg\n",
        "    |______ 14487943607_651e8062a1_m.jpg\n",
        "    |______ ...\n",
        "</pre>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7tOfUr2KlgpU"
      },
      "outputs": [],
      "source": [
        "# image_path = tf.keras.utils.get_file(\n",
        "#       'flower_photos.tgz',\n",
        "#       'https://storage.googleapis.com/download.tensorflow.org/example_images/flower_photos.tgz',\n",
        "#       extract=True)\n",
        "image_path = 'Images'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E051HBUM5owi"
      },
      "source": [
        "Use `DataLoader` class to load data.\n",
        "\n",
        "As for `from_folder()` method, it could load data from the folder. It assumes that the image data of the same class are in the same subdirectory and the subfolder name is the class name. Currently, JPEG-encoded images and PNG-encoded images are supported."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I_fOlZsklmlL"
      },
      "outputs": [],
      "source": [
        "data = DataLoader.from_folder(image_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u501eT4koURB"
      },
      "source": [
        "Split it to training data (80%), validation data (10%, optional) and testing data (10%)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cY4UU5SUobtJ"
      },
      "outputs": [],
      "source": [
        "train_data, rest_data = data.split(0.8)\n",
        "validation_data, test_data = rest_data.split(0.5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z9_MYPie3EMO"
      },
      "source": [
        "Show 25 image examples with labels."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ih4Wx44I482b"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(10,10))\n",
        "for i, (image, label) in enumerate(data.gen_dataset().unbatch().take(25)):\n",
        "  plt.subplot(5,5,i+1)\n",
        "  plt.xticks([])\n",
        "  plt.yticks([])\n",
        "  plt.grid(False)\n",
        "  plt.imshow(image.numpy(), cmap=plt.cm.gray)\n",
        "  plt.xlabel(data.index_to_label[label.numpy()])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AWuoensX4vDA"
      },
      "source": [
        "### Step 2: Customize the TensorFlow Model\n",
        "\n",
        "Create a custom image classifier model based on the loaded data. The default model is EfficientNet-Lite0.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TvYSUuJY3QxR"
      },
      "outputs": [],
      "source": [
        "model = image_classifier.create(train_data, validation_data=validation_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4JFOKWnH9x8_"
      },
      "source": [
        "Have a look at the detailed model structure."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QNXAfjl192dC"
      },
      "outputs": [],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LP5FPk_tOxoZ"
      },
      "source": [
        "### Step 3: Evaluate the Customized Model\n",
        "\n",
        "Evaluate the result of the model, get the loss and accuracy of the model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A8c2ZQ0J3Riy"
      },
      "outputs": [],
      "source": [
        "loss, accuracy = model.evaluate(test_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6ZCrYOWoCt05"
      },
      "source": [
        "We could plot the predicted results in 100 test images. Predicted labels with red color are the wrong predicted results while others are correct."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n9O9Kx7nDQWD"
      },
      "outputs": [],
      "source": [
        "# A helper function that returns 'red'/'black' depending on if its two input\n",
        "# parameter matches or not.\n",
        "def get_label_color(val1, val2):\n",
        "  if val1 == val2:\n",
        "    return 'black'\n",
        "  else:\n",
        "    return 'red'\n",
        "\n",
        "# Then plot 100 test images and their predicted labels.\n",
        "# If a prediction result is different from the label provided label in \"test\"\n",
        "# dataset, we will highlight it in red color.\n",
        "plt.figure(figsize=(20, 20))\n",
        "predicts = model.predict_top_k(test_data)\n",
        "for i, (image, label) in enumerate(test_data.gen_dataset().unbatch().take(100)):\n",
        "  ax = plt.subplot(10, 10, i+1)\n",
        "  plt.xticks([])\n",
        "  plt.yticks([])\n",
        "  plt.grid(False)\n",
        "  plt.imshow(image.numpy(), cmap=plt.cm.gray)\n",
        "\n",
        "  predict_label = predicts[i][0][0]\n",
        "  color = get_label_color(predict_label,\n",
        "                          test_data.index_to_label[label.numpy()])\n",
        "  ax.xaxis.label.set_color(color)\n",
        "  plt.xlabel('Predicted: %s' % predict_label)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S3H0rkbLUZAG"
      },
      "source": [
        "If the accuracy doesn't meet the app requirement, one could refer to [Advanced Usage](#scrollTo=zNDBP2qA54aK) to explore alternatives such as changing to a larger model, adjusting re-training parameters etc."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aeHoGAceO2xV"
      },
      "source": [
        "### Step 4: Export to TensorFlow Lite Model\n",
        "\n",
        "Convert the trained model to TensorFlow Lite model format with [metadata](https://www.tensorflow.org/lite/models/convert/metadata) so that you can later use in an on-device ML application. The label file and the vocab file are embedded in metadata. The default TFLite filename is `model.tflite`.\n",
        "\n",
        "In many on-device ML application, the model size is an important factor. Therefore, it is recommended that you apply quantize the model to make it smaller and potentially run faster.\n",
        "The default post-training quantization technique is full integer quantization for the image classification task."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Im6wA9lK3TQB"
      },
      "outputs": [],
      "source": [
        "model.export(export_dir='.')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ROS2Ay2jMPCl"
      },
      "source": [
        "See the image classification [examples guide](https://www.tensorflow.org/lite/examples/image_classification/overview) for more details about how to integrate the TensorFlow Lite model into mobile apps.\n",
        "\n",
        "This model can be integrated into an Android or an iOS app using the [ImageClassifier API](https://www.tensorflow.org/lite/inference_with_metadata/task_library/image_classifier) of the [TensorFlow Lite Task Library](https://www.tensorflow.org/lite/inference_with_metadata/task_library/overview)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "habFnvRxxQ4A"
      },
      "source": [
        "The allowed export formats can be one or a list of the following:\n",
        "\n",
        "*   `ExportFormat.TFLITE`\n",
        "*   `ExportFormat.LABEL`\n",
        "*   `ExportFormat.SAVED_MODEL`\n",
        "\n",
        "By default, it just exports TensorFlow Lite model with metadata. You can also selectively export different files. For instance, exporting only the label file as follows:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BvxWsOTmKG4P"
      },
      "outputs": [],
      "source": [
        "model.export(export_dir='.', export_format=ExportFormat.LABEL)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-4jQaxyT5_KV"
      },
      "source": [
        "You can also evaluate the tflite model with the `evaluate_tflite` method."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S1YoPX5wOK-u"
      },
      "outputs": [],
      "source": [
        "model.evaluate_tflite('model.tflite', test_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zNDBP2qA54aK"
      },
      "source": [
        "## Advanced Usage\n",
        "\n",
        "The `create` function is the critical part of this library. It uses transfer learning with a pretrained model similar to the [tutorial](https://www.tensorflow.org/tutorials/images/transfer_learning).\n",
        "\n",
        "The `create` function contains the following steps:\n",
        "\n",
        "1.   Split the data into training, validation, testing data according to parameter `validation_ratio` and `test_ratio`. The default value of `validation_ratio` and `test_ratio` are `0.1` and `0.1`.\n",
        "2.   Download a [Image Feature Vector](https://www.tensorflow.org/hub/common_signatures/images#image_feature_vector) as the base model from TensorFlow Hub. The default pre-trained model is  EfficientNet-Lite0.\n",
        "3.   Add a classifier head with a Dropout Layer with `dropout_rate` between head layer and pre-trained model. The default `dropout_rate` is the default `dropout_rate` value from [make_image_classifier_lib](https://github.com/tensorflow/hub/blob/master/tensorflow_hub/tools/make_image_classifier/make_image_classifier_lib.py#L55) by TensorFlow Hub.\n",
        "4.   Preprocess the raw input data. Currently, preprocessing steps including normalizing the value of each image pixel to model input scale and resizing it to model input size.   EfficientNet-Lite0 have the input scale `[0, 1]` and the input image size `[224, 224, 3]`.\n",
        "5.   Feed the data into the classifier model. By default, the training parameters such as training epochs, batch size, learning rate, momentum are the default values from [make_image_classifier_lib](https://github.com/tensorflow/hub/blob/master/tensorflow_hub/tools/make_image_classifier/make_image_classifier_lib.py#L55) by TensorFlow Hub. Only the classifier head is trained.\n",
        "\n",
        "\n",
        "In this section, we describe several advanced topics, including switching to a different image classification model, changing the training hyperparameters etc.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gc4Jk8TvBQfm"
      },
      "source": [
        "## Customize Post-training quantization on the TensorFLow Lite model\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tD8BOYrHBiDt"
      },
      "source": [
        "[Post-training quantization](https://www.tensorflow.org/lite/performance/post_training_quantization) is a conversion technique that can reduce model size and inference latency, while also improving CPU and hardware accelerator inference speed, with a little degradation in model accuracy. Thus, it's widely used to optimize the model.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iyIo0d5TCzE2"
      },
      "source": [
        "Model Maker library applies a default post-training quantization techique when exporting the model. If you want to customize post-training quantization, Model Maker supports multiple post-training quantization options using [QuantizationConfig](https://www.tensorflow.org/lite/api_docs/python/tflite_model_maker/config/QuantizationConfig) as well. Let's take float16 quantization as an instance. First, define the quantization config."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k8hL2mstCxQl"
      },
      "outputs": [],
      "source": [
        "config = QuantizationConfig.for_float16()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K1gzx_rmFMOA"
      },
      "source": [
        "Then we export the TensorFlow Lite model with such configuration."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WTJzFQnJFMjr"
      },
      "outputs": [],
      "source": [
        "model.export(export_dir='.', tflite_filename='model_fp16.tflite', quantization_config=config)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Safo0e40wKZW"
      },
      "source": [
        "In Colab, you can download the model named `model_fp16.tflite` from the left sidebar, same as the uploading part mentioned above."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A4kiTJtZ_sDm"
      },
      "source": [
        "## Change the model\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "794vgj6ud7Ep"
      },
      "source": [
        "### Change to the model that's supported in this library.\n",
        "\n",
        "This library supports  EfficientNet-Lite models, MobileNetV2, ResNet50 by now. [EfficientNet-Lite](https://github.com/tensorflow/tpu/tree/master/models/official/efficientnet/lite) are a family of image classification models that could achieve state-of-art accuracy and suitable for Edge devices. The default model is EfficientNet-Lite0.\n",
        "\n",
        "We could switch model to MobileNetV2 by just setting parameter `model_spec` to the MobileNetV2 model specification in `create` method."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7JKsJ6-P6ae1"
      },
      "outputs": [],
      "source": [
        "model = image_classifier.create(train_data, model_spec=model_spec.get('mobilenet_v2'), validation_data=validation_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gm_B1Wv08AxR"
      },
      "source": [
        "Evaluate the newly retrained MobileNetV2 model to see the accuracy and loss in testing data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lB2Go3HW8X7_"
      },
      "outputs": [],
      "source": [
        "loss, accuracy = model.evaluate(test_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vAciGzVWtmWp"
      },
      "source": [
        "### Change to the model in TensorFlow Hub\n",
        "\n",
        "Moreover, we could also switch to other new models that inputs an image and outputs a feature vector with TensorFlow Hub format.\n",
        "\n",
        "As [Inception V3](https://tfhub.dev/google/imagenet/inception_v3/feature_vector/1) model as an example, we could define `inception_v3_spec` which is an object of [image_classifier.ModelSpec](https://www.tensorflow.org/lite/api_docs/python/tflite_model_maker/image_classifier/ModelSpec) and contains the specification of the Inception V3 model.\n",
        "\n",
        "We need to specify the model name `name`, the url of the TensorFlow Hub model `uri`. Meanwhile, the default value of `input_image_shape` is `[224, 224]`. We need to change it to `[299, 299]` for Inception V3 model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xdiMF2WMfAR4"
      },
      "outputs": [],
      "source": [
        "inception_v3_spec = image_classifier.ModelSpec(\n",
        "    uri='https://tfhub.dev/google/imagenet/inception_v3/feature_vector/1')\n",
        "inception_v3_spec.input_image_shape = [299, 299]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T_GGIoXZCs5F"
      },
      "source": [
        "Then, by setting parameter `model_spec` to `inception_v3_spec` in `create` method, we could retrain the Inception V3 model.\n",
        "\n",
        "The remaining steps are exactly same and we could get a customized InceptionV3 TensorFlow Lite model in the end."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UhZ5IRKdeex3"
      },
      "source": [
        "### Change your own custom model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "svTjlZhrCrcV"
      },
      "source": [
        "If we'd like to use the custom model that's not in TensorFlow Hub, we should create and export [ModelSpec](https://www.tensorflow.org/hub/api_docs/python/hub/ModuleSpec) in TensorFlow Hub.\n",
        "\n",
        "Then start to define `ModelSpec` object like the process above."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4M9bn703AHt2"
      },
      "source": [
        "## Change the training hyperparameters\n",
        "We could also change the training hyperparameters like `epochs`, `dropout_rate` and `batch_size` that could affect the model accuracy. The model parameters you can adjust are:\n",
        "\n",
        "\n",
        "*   `epochs`: more epochs could achieve better accuracy until it converges but training for too many epochs may lead to overfitting.\n",
        "*   `dropout_rate`: The rate for dropout, avoid overfitting. None by default.\n",
        "*   `batch_size`: number of samples to use in one training step.  None by default.\n",
        "*   `validation_data`: Validation data. If None, skips validation process. None by default.\n",
        "*   `train_whole_model`: If true, the Hub module is trained together with the classification layer on top. Otherwise, only train the top classification layer. None by default.\n",
        "*   `learning_rate`: Base learning rate. None by default.\n",
        "*   `momentum`: a Python float forwarded to the optimizer. Only used when\n",
        "      `use_hub_library` is True. None by default.\n",
        "*   `shuffle`: Boolean, whether the data should be shuffled. False by default.\n",
        "*   `use_augmentation`: Boolean, use data augmentation for preprocessing. False by default.\n",
        "*   `use_hub_library`: Boolean, use `make_image_classifier_lib` from tensorflow hub to retrain the model. This training pipeline could achieve better performance for complicated dataset with many categories. True by default.\n",
        "*   `warmup_steps`: Number of warmup steps for warmup schedule on learning rate. If None, the default warmup_steps is used which is the total training steps in two epochs. Only used when `use_hub_library` is False. None by default.\n",
        "*   `model_dir`: Optional, the location of the model checkpoint files. Only used when `use_hub_library` is False. None by default.\n",
        "\n",
        "Parameters which are None by default like `epochs` will get the concrete default parameters in [make_image_classifier_lib](https://github.com/tensorflow/hub/blob/02ab9b7d3455e99e97abecf43c5d598a5528e20c/tensorflow_hub/tools/make_image_classifier/make_image_classifier_lib.py#L54) from TensorFlow Hub library or  [train_image_classifier_lib](https://github.com/tensorflow/examples/blob/f0260433d133fd3cea4a920d1e53ecda07163aee/tensorflow_examples/lite/model_maker/core/task/train_image_classifier_lib.py#L61).\n",
        "\n",
        "For example, we could train with more epochs.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A3k7mhH54QcK"
      },
      "outputs": [],
      "source": [
        "model = image_classifier.create(train_data, validation_data=validation_data, epochs=10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VaYBQymQDsXU"
      },
      "source": [
        "Evaluate the newly retrained model with 10 training epochs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VafIYpKWD4Sw"
      },
      "outputs": [],
      "source": [
        "loss, accuracy = model.evaluate(test_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dhBU5NCy5Ji2"
      },
      "source": [
        "# Read more\n",
        "\n",
        "You can read our [image classification](https://www.tensorflow.org/lite/examples/image_classification/overview) example to learn technical details. For more information, please refer to:\n",
        "\n",
        "*   TensorFlow Lite Model Maker [guide](https://www.tensorflow.org/lite/models/modify/model_maker) and [API reference](https://www.tensorflow.org/lite/api_docs/python/tflite_model_maker).\n",
        "*   Task Library: [ImageClassifier](https://www.tensorflow.org/lite/inference_with_metadata/task_library/image_classifier) for deployment.\n",
        "*   The end-to-end reference apps: [Android](https://github.com/tensorflow/examples/tree/master/lite/examples/image_classification/android), [iOS](https://github.com/tensorflow/examples/tree/master/lite/examples/image_classification/ios), and [Raspberry PI](https://github.com/tensorflow/examples/tree/master/lite/examples/image_classification/raspberry_pi).\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}