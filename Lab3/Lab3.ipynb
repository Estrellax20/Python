{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Biblioteki:"
      ],
      "metadata": {
        "id": "RB7nkoEOc8bK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from PIL import Image\n",
        "from skimage.feature import graycomatrix, graycoprops\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn import svm\n",
        "from sklearn import metrics\n",
        "from sklearn.model_selection import train_test_split\n"
      ],
      "metadata": {
        "id": "dJy5GRskchjj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Wczytywanie obrazów oraz wycinanie z nich fragmentów (czyli próbek tekstury) o zadanym rozmiarze (np. 128 x 128). Wycięte fragmenty zostały zapisane do odpowiednich katalogów."
      ],
      "metadata": {
        "id": "5eDeBeqocDtq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "initial_photos = 'Images'  # name of the directory containing the input photos\n",
        "texture_samples = 'T_images'  # the name of the directory where the iter_texture samples will be saved\n",
        "new_size_tSample = 128  # the size of each iter_texture S (128x128 pixels)\n",
        "\n",
        "for name_of_image in os.listdir(initial_photos):\n",
        "    # extracting the filename without the file extension from the name_of_image variable\n",
        "    image_without_extension = name_of_image.split(\".\")[0]\n",
        "    new_image_path = os.path.join(initial_photos, name_of_image)  # create new_path to image\n",
        "    new_text_path = os.path.join(texture_samples, image_without_extension)  # create new_path to iter_texture directory\n",
        "\n",
        "    try:  # try to create directory for Text_samples\n",
        "        os.mkdir(new_text_path)\n",
        "    except FileExistsError:\n",
        "        print('Error: Directory for T_images already exists')\n",
        "\n",
        "    open_image = Image.open(new_image_path)  # open image; assigns the opened image object to the open_image\n",
        "    # line calculates the number of iter_texture cuts in the x-direction and y-direction; divides the width of the open_image by the\n",
        "    # new_size_tSample, which represents the desired size of the iter_texture samples\n",
        "    number_of_xdirection_cuts = round(open_image.size[0] / new_size_tSample) - 1  # result is rounded to the nearest integer and assigned to the variable\n",
        "    number_of_ydirection_cuts = round(open_image.size[1] / new_size_tSample) - 1\n",
        "\n",
        "    for x in range(\n",
        "            number_of_xdirection_cuts):  # set up nested loops to iterate over the x and y coordinates of the iter_texture samples\n",
        "        for y in range(number_of_ydirection_cuts):\n",
        "            # creates a unique name for each iter_texture S by combining image_without_extension, the current\n",
        "            # x index, the underscore character (_), the current y index, and the \".jpg\" file extension\n",
        "            name_for_tSample = image_without_extension + str(x) + '_' + str(y) + '.jpg'\n",
        "            # crops a section of the open_image using the coordinates calculated based on the current x and y indices\n",
        "            # crop() - specifying the coordinates of the top-left and bottom-right corners of the desired section\n",
        "            cropped_image_by_using_coordinates = open_image.crop((x * new_size_tSample, y * new_size_tSample, (x + 1) * new_size_tSample, (y + 1) * new_size_tSample))\n",
        "            # creates the new_path where the iter_texture S will be saved by combining the texture_samples directory new_path, image_without_extension\n",
        "            # and the name_for_tSample\n",
        "            new_path = os.path.join(texture_samples, image_without_extension, name_for_tSample)\n",
        "            # saves the cropped iter_texture S as a new JPEG file at the specified new_path\n",
        "            cropped_image_by_using_coordinates.save(new_path)\n",
        "\n",
        "            # (x * new_size_tSample, y * new_size_tSample) -> top-left corner of the cropping region\n",
        "            # (x + 1) and (y + 1) are used to calculate the bottom-right corner of the cropping region by obtaining the next x and y coordinates"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4CHOCZ0sdAsw",
        "outputId": "fcc04e22-8282-44ff-b685-601ea59d2bed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: Directory for T_images already exists\n",
            "Error: Directory for T_images already exists\n",
            "Error: Directory for T_images already exists\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Wczytywanie próbek tekstury i wyznaczanie dla nich cech tekstury na\n",
        "podstawie modelu macierzy zdarzeń (ang. grey-level co-occurrence matrix) za pomocą odpowiednich funkcji z pakietu scikit-image. Przed obliczeniem cech, każdy obraz został przekształcony do skali szarości oraz została zmnniejszona głębia jasności do 5 bitów (64 poziomy)."
      ],
      "metadata": {
        "id": "oLO8V9fodLVe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "texture_samples = 'T_images'  # stores the name of the folder containing iter_texture samples\n",
        "distances_between_pixels = [1, 3,\n",
        "                            5]  # a list of distances between pixels used for the grey-level co-occurrence matrix (GLCM)\n",
        "list_of_angles = [0, np.pi / 4, np.pi / 2,\n",
        "                  (3 / 4) * np.pi]  # a list of list_of_angles used for the GLCM -> [0, 45, 90, 135]\n",
        "\n",
        "# create a dictionary res_cat to store the results specific to that category\n",
        "# iterating over the folders within the texture_samples directory using os.listdir(texture_samples)\n",
        "\n",
        "data_df = pd.DataFrame()  # create a DataFrame from the data list\n",
        "\n",
        "for Ftexture in os.listdir(texture_samples):\n",
        "    # constructs the path to the current iter_texture folder by joining the texture_samples directory path and the current folder name\n",
        "    path_for_texture_sampling = os.path.join(texture_samples, Ftexture)\n",
        "\n",
        "    for Stext in os.listdir(path_for_texture_sampling):\n",
        "        # constructs the path to the current iter_texture S file by joining the path_for_texture_sampling and the current file name (Stext)\n",
        "        Spath = os.path.join(path_for_texture_sampling, Stext)\n",
        "        # opens the image file using the Image module from the PIL library; then converts the image to grayscale ('L' mode) using the convert method\n",
        "        S = Image.open(Spath).convert('L')\n",
        "        # reduces the brightness depth of the grayscale image to 5 bits by dividing each pixel value by 4 using a lambda function and the point method\n",
        "        Sgray_reduced = S.point(lambda x: int(x / 4))\n",
        "        # converts the reduced grayscale image (Sgray_reduced) to a NumPy array (Sgray_array)\n",
        "        Sgray_array = np.array(Sgray_reduced)\n",
        "\n",
        "        # calculates the GLCM (grey-level co-occurrence matrix) using the pixel distances, list_of_angles, and levels specified\n",
        "        # Sgray_array: The reduced grayscale image array\n",
        "        # distances: A list of distances between pixels used for the GLCM\n",
        "        # list_of_angles: A list of list_of_angles at which to compute the GLCM\n",
        "        # levels: The number of gray levels to use when computing the GLCM\n",
        "        # symmetric: A boolean flag indicating whether the GLCM should be symmetric (True) or not (False)\n",
        "        GLCM_calculate = graycomatrix(Sgray_array, distances=distances_between_pixels, angles=list_of_angles, levels=64,\n",
        "                                      symmetric=True)\n",
        "\n",
        "        res_cat = pd.Series({'category': Ftexture,\n",
        "                             'dissimilarity': graycoprops(GLCM_calculate, 'dissimilarity'),\n",
        "                             'correlation': graycoprops(GLCM_calculate, 'correlation'),\n",
        "                             'contrast': graycoprops(GLCM_calculate, 'contrast'),\n",
        "                             'energy': graycoprops(GLCM_calculate, 'energy'),\n",
        "                             'homogeneity': graycoprops(GLCM_calculate, 'homogeneity'),\n",
        "                             'ASM': graycoprops(GLCM_calculate, 'ASM')\n",
        "                             })\n",
        "\n",
        "        data_df = pd.concat([data_df, res_cat.to_frame().T])  # merge arrays\n",
        "\n",
        "data_df.to_pickle('results.pkl')  # save results to .pkl file\n",
        "\n",
        "print('Thats all')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v8t4mb9OdavN",
        "outputId": "b887b16b-b811-4f4b-981e-94c4f622090b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Thats all\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "3.  Skrypt służący do klasyfikacji wektorów cech z wykorzystaniem dowolnego algorytmu klasyfikacji danych dostępnego w pakiecie scikit-learn. Zostało obliczona i wyświetlona na ekranie wyznaczona dokładność klasyfikatora."
      ],
      "metadata": {
        "id": "CXaFzg6CeWBa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Read features from the .pkl file\n",
        "features_from_pkl_file = pd.read_pickle('results.pkl')\n",
        "\n",
        "# Define the properties to extract from the file\n",
        "properties_from_file = ['dissimilarity', 'correlation', 'contrast', 'energy', 'homogeneity', 'ASM']\n",
        "\n",
        "# Extract unique iter_texture categories\n",
        "T_images = features_from_pkl_file['category'].unique()\n",
        "\n",
        "# Create empty lists for features and labels\n",
        "features = []\n",
        "labels = []\n",
        "\n",
        "# Iterate over each iter_texture category\n",
        "for iter_texture in T_images:\n",
        "    # Filter the data for the current iter_texture category\n",
        "    texture_data = features_from_pkl_file[features_from_pkl_file['category'] == iter_texture]\n",
        "\n",
        "    # Extract the properties for the current iter_texture category\n",
        "    properties = texture_data[properties_from_file].values\n",
        "\n",
        "    # Flatten and add the properties to the features list\n",
        "    features.extend([np.hstack(prop).flatten() for prop in properties])\n",
        "\n",
        "    # Add labels for each sample in the current iter_texture category\n",
        "    labels.extend([iter_texture] * len(properties))\n",
        "\n",
        "# Split the dataset into training set and test set\n",
        "x_train, x_test, y_train, y_test = train_test_split(features, labels)\n",
        "\n",
        "# Create an SVM classifier\n",
        "classifier = svm.SVC(kernel='linear')\n",
        "\n",
        "# Train the model using the training sets\n",
        "classifier.fit(x_train, y_train)\n",
        "\n",
        "# Predict the response for the test dataset\n",
        "predict_response = classifier.predict(x_test)\n",
        "\n",
        "# Calculate the model accuracy\n",
        "accuracy = metrics.accuracy_score(y_test, predict_response) * 100\n",
        "print('Accuracy:', round(accuracy, 2), '%')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SAkE75L1epZS",
        "outputId": "515844eb-d6f7-48d8-a43f-391b6afa1b50"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 100.0 %\n"
          ]
        }
      ]
    }
  ]
}