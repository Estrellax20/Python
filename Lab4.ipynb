{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Import modułów i pakietów:"
      ],
      "metadata": {
        "id": "yfkwYXDhU5q9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "siwP_YBtCKWW"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from keras import Sequential\n",
        "from keras.layers import Dense\n",
        "from sklearn import metrics\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.preprocessing import OneHotEncoder, LabelEncoder"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "Wczytywanie danych z pliku .pkl:\n",
        "  1. Wykorzystanie funkcji read_pickle z pakietu pandas\n",
        "  2. Wyodrębnienie wektorów cech do macierzy X\n",
        "  3. Wyodrębnienie etykiet kategorii do wektora y\n"
      ],
      "metadata": {
        "id": "oPGEdtvaVDl_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "61jy3AlJILSI"
      },
      "outputs": [],
      "source": [
        "# Create empty lists for features and labels\n",
        "X = []\n",
        "y = []\n",
        "\n",
        "# Read features from the .pkl file\n",
        "features_from_pkl_file = pd.read_pickle('results.pkl')\n",
        "\n",
        "# Define the properties to extract from the file\n",
        "properties_from_file = ['dissimilarity', 'correlation', 'contrast', 'energy', 'homogeneity', 'ASM']\n",
        "\n",
        "# Extract unique iter_texture categories\n",
        "T_images = features_from_pkl_file['category'].unique()\n",
        "\n",
        "# Iterate over each iter_texture category\n",
        "for iter_texture in T_images:\n",
        "    # Filter the data for the current iter_texture category\n",
        "    texture_data = features_from_pkl_file[features_from_pkl_file['category'] == iter_texture]\n",
        "\n",
        "    # Extract the properties for the current iter_texture category\n",
        "    properties = texture_data[properties_from_file].values\n",
        "\n",
        "    # Flatten and add the properties to the X list\n",
        "    X.extend([np.hstack(prop).flatten() for prop in properties])\n",
        "\n",
        "    # Add labels for each sample in the current iter_texture category\n",
        "    y.extend([iter_texture] * len(properties))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Wykonanie kodowania całkowitoliczbowego dla wektora y → y_int:"
      ],
      "metadata": {
        "id": "B9J7sXuzWOOn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "label_encoder = LabelEncoder() # Create an instance of LabelEncoder\n",
        "y_int = label_encoder.fit_transform(y) # Encode categorical labels y into numeric values and store them in y_int"
      ],
      "metadata": {
        "id": "FVW6fkZAOgze"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Wykonanie kodowania 1 z n dla wektora y_int → y_onehot:"
      ],
      "metadata": {
        "id": "lVfVlKXzWV6e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "onehot_encoder = OneHotEncoder(sparse_output=False) # Create an instance of OneHotEncoder with dense output\n",
        "y_onehot = onehot_encoder.fit_transform(y_int.reshape(-1, 1)) # One-hot encode the integer-encoded labels y_int"
      ],
      "metadata": {
        "id": "Hts6ksXLO9eb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Podzielenie zbioru X oraz wektora etykiet y_onehot na część treningową (70%) i testową (30%):"
      ],
      "metadata": {
        "id": "g_BNNvRUWgMD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y_onehot, test_size=0.3) # Split the dataset and one-hot encoded labels into training and testing sets"
      ],
      "metadata": {
        "id": "axQHk2slPE50"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tworzenie modelu sieci neuronowej:\n",
        "\n",
        "  1. Utworzenie obiektu sieci typu Sequential\n",
        "  2. Dodanie dwóch warstw typu Dense. W pierwszej warstwie ustawienie liczby perceptronów na 10, funkcja aktywacji - sigmoid, wymiar wejściowy - input_dim = 72 (tyle, ile jest cech w zbiorze danych). W drugiej warstwie ustawienie liczby neuronów na 3 (tyle ile jest klas) oraz funkcji aktywacji na softmax.\n",
        "  3. Skompilowanie modelu z funkcją straty categorical_crossentropy oraz algorytmem optymalizacji: sgd (=stochastic gradient descent). Dodanie accuracy jako metryki wyliczanej w trakcie uczenia.\n",
        "\n"
      ],
      "metadata": {
        "id": "sbUxxkEgXP5T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential() # Create a sequential model\n",
        "model.add(Dense(10, activation='sigmoid', input_dim=72)) # Add a dense layer with 10 units, sigmoid activation, and input dimension of 72\n",
        "model.add(Dense(3, activation='softmax')) # Add a dense layer with 3 units and softmax activation\n",
        "model.compile(loss='categorical_crossentropy', optimizer='sgd', metrics=['accuracy']) # Compile the model with categorical cross-entropy loss, SGD optimizer, and accuracy metric"
      ],
      "metadata": {
        "id": "gMktsvQZPkHv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Uczenie sieci - wywołanie na rzecz modelu funkcji fit:"
      ],
      "metadata": {
        "id": "R-m6l1giX-ZS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = np.asarray(X_train).astype(np.float32) # Convert X_train to a NumPy array of type float32\n",
        "model.fit(X_train, y_train, epochs=100, batch_size=10, shuffle=True) # Fit the model to the training data"
      ],
      "metadata": {
        "id": "tCawmh-XPpMN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8857e8ff-cb7f-4273-8904-0af5e7c5507b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 2.1880 - accuracy: 0.1562\n",
            "Epoch 2/100\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 1.8885 - accuracy: 0.1562\n",
            "Epoch 3/100\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 1.6899 - accuracy: 0.1562\n",
            "Epoch 4/100\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 1.5380 - accuracy: 0.1562\n",
            "Epoch 5/100\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 1.3957 - accuracy: 0.1562\n",
            "Epoch 6/100\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 1.3054 - accuracy: 0.1562\n",
            "Epoch 7/100\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 1.1881 - accuracy: 0.1562\n",
            "Epoch 8/100\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 1.1051 - accuracy: 0.1562\n",
            "Epoch 9/100\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 1.0250 - accuracy: 0.1562\n",
            "Epoch 10/100\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.9612 - accuracy: 0.3438\n",
            "Epoch 11/100\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.8775 - accuracy: 0.3125\n",
            "Epoch 12/100\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.9302 - accuracy: 0.6250\n",
            "Epoch 13/100\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.8906 - accuracy: 0.6875\n",
            "Epoch 14/100\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.8656 - accuracy: 0.6875\n",
            "Epoch 15/100\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.8111 - accuracy: 0.6875\n",
            "Epoch 16/100\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.7861 - accuracy: 0.6875\n",
            "Epoch 17/100\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.8311 - accuracy: 0.5938\n",
            "Epoch 18/100\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.7717 - accuracy: 0.6562\n",
            "Epoch 19/100\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.7339 - accuracy: 0.6562\n",
            "Epoch 20/100\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.6968 - accuracy: 0.7500\n",
            "Epoch 21/100\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.6801 - accuracy: 0.6875\n",
            "Epoch 22/100\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.6559 - accuracy: 0.7812\n",
            "Epoch 23/100\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.6498 - accuracy: 0.7812\n",
            "Epoch 24/100\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.6405 - accuracy: 0.7812\n",
            "Epoch 25/100\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.6350 - accuracy: 0.7188\n",
            "Epoch 26/100\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.6141 - accuracy: 0.7812\n",
            "Epoch 27/100\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.5838 - accuracy: 0.7500\n",
            "Epoch 28/100\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.7227 - accuracy: 0.6875\n",
            "Epoch 29/100\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.6793 - accuracy: 0.6562\n",
            "Epoch 30/100\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.6196 - accuracy: 0.6875\n",
            "Epoch 31/100\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.5822 - accuracy: 0.8438\n",
            "Epoch 32/100\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.5828 - accuracy: 0.7812\n",
            "Epoch 33/100\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.5622 - accuracy: 0.7500\n",
            "Epoch 34/100\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.6314 - accuracy: 0.7188\n",
            "Epoch 35/100\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.6749 - accuracy: 0.6562\n",
            "Epoch 36/100\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.5252 - accuracy: 0.7500\n",
            "Epoch 37/100\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.5809 - accuracy: 0.7812\n",
            "Epoch 38/100\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.5396 - accuracy: 0.8438\n",
            "Epoch 39/100\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.5190 - accuracy: 0.8438\n",
            "Epoch 40/100\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.4860 - accuracy: 0.8438\n",
            "Epoch 41/100\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.5839 - accuracy: 0.7812\n",
            "Epoch 42/100\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.5247 - accuracy: 0.8438\n",
            "Epoch 43/100\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.4781 - accuracy: 0.8438\n",
            "Epoch 44/100\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.4667 - accuracy: 0.8438\n",
            "Epoch 45/100\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.4726 - accuracy: 0.8438\n",
            "Epoch 46/100\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.4795 - accuracy: 0.8438\n",
            "Epoch 47/100\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.5228 - accuracy: 0.8438\n",
            "Epoch 48/100\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.4914 - accuracy: 0.7812\n",
            "Epoch 49/100\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.4479 - accuracy: 0.8438\n",
            "Epoch 50/100\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.4542 - accuracy: 0.8438\n",
            "Epoch 51/100\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.4395 - accuracy: 0.8438\n",
            "Epoch 52/100\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.4301 - accuracy: 0.8438\n",
            "Epoch 53/100\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.4712 - accuracy: 0.7812\n",
            "Epoch 54/100\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.4264 - accuracy: 0.8438\n",
            "Epoch 55/100\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.4223 - accuracy: 0.8750\n",
            "Epoch 56/100\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.4211 - accuracy: 0.8438\n",
            "Epoch 57/100\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.4718 - accuracy: 0.7812\n",
            "Epoch 58/100\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.4227 - accuracy: 0.8438\n",
            "Epoch 59/100\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.4096 - accuracy: 0.9375\n",
            "Epoch 60/100\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.4220 - accuracy: 0.9062\n",
            "Epoch 61/100\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.4004 - accuracy: 0.8750\n",
            "Epoch 62/100\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.4939 - accuracy: 0.9375\n",
            "Epoch 63/100\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.4664 - accuracy: 0.9062\n",
            "Epoch 64/100\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.3939 - accuracy: 0.9375\n",
            "Epoch 65/100\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3941 - accuracy: 0.8750\n",
            "Epoch 66/100\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.3982 - accuracy: 0.9375\n",
            "Epoch 67/100\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.4010 - accuracy: 0.9062\n",
            "Epoch 68/100\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3829 - accuracy: 0.9688\n",
            "Epoch 69/100\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3820 - accuracy: 0.9375\n",
            "Epoch 70/100\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.4552 - accuracy: 0.8125\n",
            "Epoch 71/100\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.3844 - accuracy: 0.9375\n",
            "Epoch 72/100\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.3736 - accuracy: 0.9688\n",
            "Epoch 73/100\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3665 - accuracy: 1.0000\n",
            "Epoch 74/100\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3663 - accuracy: 1.0000\n",
            "Epoch 75/100\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.3672 - accuracy: 1.0000\n",
            "Epoch 76/100\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.3615 - accuracy: 1.0000\n",
            "Epoch 77/100\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.3633 - accuracy: 0.9688\n",
            "Epoch 78/100\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.3549 - accuracy: 1.0000\n",
            "Epoch 79/100\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.3520 - accuracy: 1.0000\n",
            "Epoch 80/100\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.3505 - accuracy: 1.0000\n",
            "Epoch 81/100\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3523 - accuracy: 0.9688\n",
            "Epoch 82/100\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3461 - accuracy: 1.0000\n",
            "Epoch 83/100\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.3461 - accuracy: 1.0000\n",
            "Epoch 84/100\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3413 - accuracy: 1.0000\n",
            "Epoch 85/100\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.3380 - accuracy: 1.0000\n",
            "Epoch 86/100\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.3369 - accuracy: 1.0000\n",
            "Epoch 87/100\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.3340 - accuracy: 1.0000\n",
            "Epoch 88/100\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3343 - accuracy: 1.0000\n",
            "Epoch 89/100\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3467 - accuracy: 0.9688\n",
            "Epoch 90/100\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.3294 - accuracy: 1.0000\n",
            "Epoch 91/100\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.3251 - accuracy: 1.0000\n",
            "Epoch 92/100\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.3265 - accuracy: 1.0000\n",
            "Epoch 93/100\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.3214 - accuracy: 1.0000\n",
            "Epoch 94/100\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.3172 - accuracy: 1.0000\n",
            "Epoch 95/100\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3167 - accuracy: 1.0000\n",
            "Epoch 96/100\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3146 - accuracy: 1.0000\n",
            "Epoch 97/100\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.3140 - accuracy: 1.0000\n",
            "Epoch 98/100\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3098 - accuracy: 1.0000\n",
            "Epoch 99/100\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3090 - accuracy: 1.0000\n",
            "Epoch 100/100\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3068 - accuracy: 1.0000\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f43bf78b070>"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Testowanie sieci:\n",
        "\n",
        "  1. Przekonwertowanie wektora y_test oraz y_pred do kodowania całkowitego.\n",
        "  2. Na podstawie otrzymanych wektorów etykiet całkowitoliczbowych wyliczenie macierz pomyłek.\n",
        "\n"
      ],
      "metadata": {
        "id": "GdGRQROjYGS1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_test = np.asarray(X_test) # Convert X_test to a NumPy array\n",
        "y_pred = model.predict(X_test) # Make predictions on the test data\n",
        "y_test_int = np.argmax(y_test, axis=1) # Convert the one-hot encoded test labels to integer labels\n",
        "y_pred_int = np.argmax(y_pred, axis=1) # Convert the predicted probabilities to integer labels\n",
        "cm = metrics.confusion_matrix(y_test_int, y_pred_int) # Compute the confusion matrix\n",
        "print(cm)"
      ],
      "metadata": {
        "id": "qFokkf_VPvoF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ee857de3-2e6c-42f9-9c0b-14beed848a88"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 55ms/step\n",
            "[[4 0 0]\n",
            " [0 3 0]\n",
            " [0 0 7]]\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}